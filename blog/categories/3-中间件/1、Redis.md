---
title: 缓存数据库Redis的学习记录
date: 2022-08-16
description: Redis 是一个开源的 key-value 存储系统（内存高速缓存数据库）。和 Memcached类似，它支持存储的 value 类型相对更多，包括 string(字符串)、list(链表)、set(集合)、zset(sorted set --有序集合)和 hash（哈希类型）。这些数据类型都支持 push/pop、add/remove 及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。在此基础上，Redis 支持各种不同方式的排序。与 memcached 一样，为了保证效率，数据都是缓存在内存中。区别的是 Redis 会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件。并且在此基础上实现了master-slave(主从)同步。
tags:
 - Redis
categories:
 - 中间件
publish: true
---

## 一、概念和基础

### 1.1、什么是Redis？

**Redis** 是一个开源的 `key-value 存储系统`（内存高速缓存数据库）。和 `Memcached `类似，它支持存储的 value 类型相对更多，包括 `string(字符串)`、`list(链表)`、`set(集合)`、`zset(sorted set --有序集合)`和 `hash（哈希类型）`。这些数据类型都支持 `push/pop、add/remove` 及取交集并集和差集及更丰富的操作，而且这些操作都是**原子性**的。在此基础上，Redis 支持各种不同方式的排序。与 memcached 一样，为了保证效率，数据都是**缓存在内存中**。区别的是 Redis 会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件。并且在此基础上实现了`master-slave(主从)同步`。

可用于缓存、事件发布或订阅、高速队列等场景。支持网络、提供字符串、哈希、列表、队列、集合结构直接存取，基于内存，可持久化。

**配合关系型数据库做高速缓存**

- 高频次，热门访问的数据，降低数据库 IO 
- 分布式架构，做 session 共享

**多样的数据结构存储持久化数据**

<img src="https://oss.zhulinz.top//img/image-20220521193155461.png" alt="image-20220521193155461"/>

**redis介绍**

- 默认 16 个数据库，类似数组下标从 0 开始，初始默认使用 0 号库 
- 使用命令` select <dbid> `来切换数据库。如: select 8 
- 统一密码管理，所有库同样密码。 
- dbsize 查看当前数据库的 key 的数量 
- flushdb 清空当前库 
- flushall 通杀全部库

### 1.2、为什么用Redis？

redis的特点：

- **读写性能优异：**读的速度是110000次/s，写的速度是81000次/s。
- **数据类型丰富：**支持二进制案例的 Strings、Lists、Sets、Hashs及ZSets数据类型操作。
- **原子性：**所有操作都是原子性的，同时Redis还支持对几个操作全并后的原子性执行。
- **丰富的特性：**支持 publish/subscribe，通知，key过期等特性。
- **持久化：**支持RDB、AOF及混合模式持久化方式。
- **发布订阅：**支持发布/订阅模式。
- **分布式：**Redis Cluster。

### 1.3、Redis为什么快？

- **基于内存实现**
- **高效的数据结构**
- **合理的数据编码**
- **合理的线程模型**
- **虚拟内存机制**

> **1、Redis的单线程与多路IO复用机制** 

`多路复用`是指使用**一个线程来检查多个文件描述符（Socket）的就绪状态**，比如调用select 和 poll 函数，传入多个文件描述符，如果有一个文件描述符就绪，则返回，否则阻塞直到超时。得到就绪状态后进行真正的操作可以在同一个线程里执行，也可以启动线程执行（比如使用线程池） 串行 vs 多线程+锁（memcached） vs 单线程+多路 IO 复用(Redis)。

（与 Memcache 三点不同: `支持多数据类型`，`支持持久化`，`单线程+多路 IO 复用`）。

<img src="https://oss.zhulinz.top//img/image-20220521194217299.png" alt="image-20220521194217299"/>

Redis是`单线程`，主要是指**Redis的网络IO和键值对读写**是由一个线程来完成的，这也是Redis对外提供键值存储服务的主要流程。Redis的其他功能，如持久化、异步删除、集群数据同步等，是由额外的线程执行的。

Redis在启动的时候，是会**启动后台线程（BIO）的**。

- `Redis在 2.6 版本`，会启动2个后台线程，分别`处理关闭文件`、`AOF刷盘`这两个任务。
- `Redis在 4.0 版主之后`，新增了一个后台线程，用来`异步释放Redis内存`，也就是`lazyfree`线程。例如执行 `unlink key / flushdb async / flushall async`等命令，会把这些删除操作交给`后台线程`来执行。好处是不会**导致Redis主线程卡顿**。因此，要删除一个大key时，不要使用`del`命令删除，因为`del是在主线程处理`的，会导致Redis主线程卡顿。应该使用` unlink `命令来异步删除。

后台线程相当于一个消费者，生产者把耗时任务丢到任务队列中，消费者（BIO）不停轮询这个队列，拿出任务就去执行对应的方法即可。

![image-20220725134733751](https://oss.zhulinz.top//img/202207311050325.png)

`关闭文件`、`AOF 刷盘`、`释放内存`这三个任务都有各自的任务队列：

- **BIO_CLOSE_FILE，关闭文件任务队列：**当队列有任务后，后台线程会调用` close(fd) `，将文件关闭；
- **BIO_AOF_FSYNC，AOF刷盘任务队列：**当 AOF 日志配置成` everysec `选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到队列中。当发现队列有任务后，后台线程会调用` fsync(fd)`，将 AOF 文件刷盘。
- **BIO_LAZY_FREE，lazy free 任务队列：**当队列有任务后，后台线程会` free(obj) 释放对象 / free(dict) 删除数据库所有对象 / free(skiplist) 释放跳表对象`。

> **2、Redis为什么使用单线程？**

为了避免不必要的多线程频繁切换上下文，多线程的设计会增加系统的复杂度。且Redis的性能瓶颈不在于CPU，而在于机器的内存大小。

多线程的开销问题。使用多线程，可以增加系统吞吐率，或是可以增加系统扩展性；对于一个多线程的系统来说，在有合理的资源分配的情况下，可以增加系统中处理请求操作的资源实体，进而提升系统能够同时处理的请求数。采用多线程后，系统的吞吐率可能会稳步增加，但是没有良好的系统设计的话，在后期，随着线程数的增加，系统吞吐率的增长就迟缓了。该情况的原因在于，系统中通常会存在被多线程同时访问的共享资源，比如一个共享的数据结构。当有多个线程要修改这个共享资源时，为了保证共享资源的正确性，就需要有额外的机制进行保证，而这个额外的机制，就会带来额外的开销。

所有在Redis的开发中，采用多线程开发一般会引入同步原语来保护共享资源的并发访问，如此会降低系统代码的易调试性和可维护性。

> **3、单线程Redis效率高的原因？**

Redis的大部分操作在内存上完成，且采用了高效的数据结构（哈希表和跳表）；Redis采用了IO多路复用机制，使其在网络IO操作中能并发处理大量的客户端请求，实现吞吐率。

**IO多路复用**

以 Get 请求为例，SimpleKV 为了处理一个 Get 请求，需要监听客户端请求（bind/listen），和客户端建立连接（accept），从 socket 中读取请求（recv），解析客户端发送请求（parse），根据请求类型读取键值数据（get），最后给客户端返回结果，即向 socket 中写回数据（send）。

下图显示了这一过程，其中，bind/listen、accept、recv、parse 和 send 属于网络 IO 处理，而 get 属于键值数据操作。既然 Redis 是单线程，那么，最基本的一种实现是在一个线程中依次执行上面说的这些操作。

![image-20220724091958903](https://oss.zhulinz.top//img/202207240920145.png)

但是，在这里的网络 IO 操作中，有潜在的阻塞点，分别是 accept() 和 recv()。当 Redis 监听到一个客户端有连接请求，但一直未能成功建立起连接时，会阻塞在 accept() 函数这里，导致其他客户端无法和 Redis 建立连接。类似的，当 Redis 通过 recv() 从一个客户端读取数据时，如果数据一直没有到达，Redis 也会一直阻塞在 recv()。

这就导致 Redis 整个线程阻塞，无法处理其他客户端请求，效率很低。不过，幸运的是，socket 网络模型本身支持非阻塞模式。

> **4、Redis的线程模型**

![redis单线程模型.drawio](https://oss.zhulinz.top//img/202207251351835.webp)

蓝色部分是一个事件循环，由主线程负责，可以看到`网络I/O和命令处理`都是单线程。Redis初始化时：

1. 调用` epoll_create() `创建一个 epoll 对象和调用 socket() 一个服务端 socket。
2. 调用` bind() `绑定端口和调用` listen() `监听该 socket。
3. 调用` epoll_ctl() `将` listem socket `加入到 epoll，同时**注册连接事件**处理函数。

在初始化完成后，主线程就会进入到一个`事件循环函数`中

1. 首先，会调用处理发送队列函数，看发送队列里是否有任务，如果有发送任务，则通过` write `函数将客户端发送缓存区里的数据发送出去。如果这一轮数据没有发送完，就会注册写事件处理函数，等待` epoll_wait `发现可写后再处理。
2. 接着，调用` epoll_wait `函数等待事件的到来：
   1. 如果是**连接事件**到来，则会调用连接事件处理函数，该函数的作用：调用 accept 获取已连接的 socket -> 调用 epoll_ctl将已连接的 socket 加入到 epoll -> 注册读事件处理函数。
   2. 如果是**读事件**到来，则会调用读事件处理函数，该函数的作用：调用 read 获取客户端发送的数据 -> 解析命令 -> 处理命令 -> 将客户端对象添加到发送队列中 -> 将执行结果写到发送缓存区等待发送。
   3. 如果是**写事件**到来，则会调用写事件处理函数，该函数的作用：通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发送完，就会继续注册写事件处理函数，等待 epoll_wait 发现可写后再去处理。

### 1.4、Redis的适用场景

> **1、热点数据的缓存**

由于Redis`读写性能优异`，比较适用于数据的缓存。且内部是`支持事务`的，在使用时能有效`保证数据的一致性`。

两种方案作为缓存保存数据：

- 读取前，先去读Redis。如果没有数据，则去数据库读取数据，再将数据保存进Redis。`（先读再存）`

  **注意：**

  - 避免缓存击穿（数据库没有需要命中的数据，导致Redis一直没有数据，且请求一直命中数据库）。
  - 数据的实时性相对会差一点。
  - 适用于数据实时性要求不是特别高的场景。

- 插入数据时，同时写入Redis。

  **注意：**

  - 数据实时性强，但是开发时不便于统一管理。
  - 适用于字典表、数据量不大的数据存储。

> **2、限时业务的运用**

可以利用 expire 命令设置一个键的生存时间，到期后redis会删除它。利用该特性可以运用在限时的优惠活动信息、手机验证码等业务场景。

> **3、计数器相关问题**

由于 incrby 命令可以实现原子性的递增，所以可以运用于高并发的秒杀活动、分布式序列号的生成、具体业务还体现在比如限制一个手机号发多少条短信、一个接口一分钟限制多少请求、一个接口一条限制调用多少次等等。

> **4、分布式锁**

主要利用 setnx 命令进行。setnx：“set if not exists”就是如果不存在则成功设置缓存同时返回1，否则返回0。由于服务器是集群的，定时任务可能在两台机器上都会运行，所以在定时任务中首先通过 setnx 设置一个lock，如果成功设置则执行，没有则表明该定时任务已执行。可以给lock加一个过期时间，比如30分钟执行一次的定时任务，那么这个过期时间设置为小于30分钟的一个时间就可以，这个与定时任务的周期以及定时任务执行消耗时间相关。

> **5、延时操作**

比如在订单生产后占用了库存，10分钟后去检验用户是否真正购买，如果没有购买则将单据设置无效，同时还原库存。

由于redis自2.8.0之后版本提供`Keyspace Notifications`功能，`允许客户订阅Pub/Sub频道`，以便以某种方式接收影响Redis数据集的事件。 所以我们对于上面的需求就可以用以下解决方案，我们在订单生产时，设置一个key，同时设置10分钟后过期， 我们在后台实现一个监听器，监听key的实效，监听到key失效时将后续逻辑加上。

> **6、排行榜相关问题**

关系型数据库在排行榜方面查询速度普遍偏慢，因此可以借助redis的**ZSet进行热点数据的排序。**

**点赞排行榜：**做一个ZSet，然后以`用户的openId作为上面的username`，以`用户的点赞数作为上面的score`，然后针对每一个用户做一个`hash`，通过`zrangebyscore`命令就可以按照点赞数获取排行榜，最后再根据`username`获取用户的`hash信息`。

> **7、点赞、好友等相互关系的存储**

Redis可以利用集合的一些命令，比如求交集、并集、差集等。

在微博应用中，每个用户关注的人存在一个集合中，就很容易实现求两个人的共同好友功能。

> **8、简单队列**

redis的list push和list pop命令来实现队列。

## 二、数据结构

### 2.1、五种基础类型

![image-20220731113607662](https://oss.zhulinz.top//img/202207311136643.png)

| 结构类型         | 结构存储的值                               | 结构的读写能力                                               |
| ---------------- | ------------------------------------------ | ------------------------------------------------------------ |
| **String字符串** | 可以是字符串、整数或浮点数                 | 对整个字符串或字符串的一部分进行操作；对整数或浮点数进行自增或自减操作； |
| **List列表**     | 一个链表，链表上的每个节点都包含一个字符串 | 对链表的两端进行push和pop操作，读取单个或多个元素；根据值查找或删除元素； |
| **Set集合**      | 包含字符串的无序集合                       | 字符串的集合，包含基础的方法有看是否存在添加、获取、删除；还包含计算交集、并集、差集等 |
| **Hash散列**     | 包含键值对的无序散列表                     | 包含方法有添加、获取、删除单个元素                           |
| **Zset有序集合** | 和散列一样，用于存储键值对                 | 字符串成员与浮点数分数之间的有序映射；元素的排列顺序由分数的大小决定；包含方法有添加、获取、删除单个元素以及根据分值范围或成员来获取元素 |

#### 键（key）

```tex
keys *				查看当前库所有 key (匹配：keys *1) 
exists key			判断某个 key 是否存在 
type key		  	查看你的 key 是什么类型 
del key				删除指定的 key 数据 
unlink key			根据 value		选择非阻塞删除		仅将 keys 从 keyspace 元数据中删除，真正的删除会在后续异步操作。 
expire key 10		10 秒钟：为给定的 key 设置过期时间 
ttl key				查看还有多少秒过期，-1 表示永不过期，-2 表示已过期 
select			 	命令切换数据库 
dbsizex				查看当前数据库的 key 的数量 
flushdb				清空当前库 
flushall		  	通杀全部库 
```

#### 字符串（String）

- String 是 Redis 最基本的类型，你可以理解成与 Memcached 一模一样的类型，`一个 key对应一个 value`。 
- String 类型是**二进制安全**的。意味着 Redis 的 string 可以**包含任何数据**。比如 jpg 图片或者序列化的对象。 
- String 类型是 Redis 最基本的数据类型，一个 Redis 中字符串 value 最多可以是 **512M**。

```tex
set <key><value>							添加键值对
get <key>									查询对应键值 
append <key><value>				  			将给定的<value> 追加到原值的末尾 
strlen <key>								获得值的长度 
setnx <key><value>							只有在 key 不存在时 设置 key 的值
incr <key> 			        				将 key 中储存的数字值增 1 只能对数字值操作，如果为空，新增值为 1 
decr <key> 				 					将 key 中储存的数字值减 1 只能对数字值操作，如果为空，新增值为-1 
incrby / decrby <key><步长>				   将 key 中储存的数字值增减。自定义步长。
mset <key1><value1><key2><value2> .....		同时设置一个或多个 key-value 对 
mget <key1><key2><key3> .....				同时获取一个或多个 value 
msetnx <key1><value1><key2><value2> .....	同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在。
			原子性，有一个失败则都失败
getrange <key><起始位置><结束位置>			  获得值的范围，类似 java 中的 substring，前包，后包 
setrange <key><起始位置><value>				 用 <value> 覆写<key>所储存的字符串值，从<起始位置>开始(索引从 0 开始)。 
setex <key><过期时间><value>				 设置键值的同时，设置过期时间，单位秒。 
getset <key><value>							以新换旧，设置了新值同时获得旧值。
```

**原子性** 

所谓**原子**操作是指不会被线程调度机制打断的操作；这种操作一旦开始，就一直运行到结束，中间不会有任何 context switch （切换到另一个线程）。 

- 在单线程中， 能够在单条指令中完成的操作都可以认为是"原子操作"，因为中断只能发生于指令之间。 
- 在多线程中，不能被其它进程（线程）打断的操作就叫原子操作。Redis 单命令的原子性主要得益于 Redis 的单线程。 

**案例：** 

java 中的 i++是否是原子操作？**不是** 

i=0;两个线程分别对 i 进行++100 次,值是多少？ **2~200**

<img src="https://oss.zhulinz.top//img/image-20220522112446066.png" alt="image-20220522112446066"/>

##### 数据结构

String 的数据结构为`简单动态字符串`(Simple Dynamic String,缩写 SDS)。是可以修改的字符串，内部结构实现上类似于 Java 的 `ArrayList`，采用**预分配冗余空间**的方式来减少内存的频繁分配.

<img src="https://oss.zhulinz.top//img/image-20220522112539492.png" alt="image-20220522112539492"/>

如图中所示，内部为当前字符串实际分配的空间 `capacity `一般要**高于实际字符串长度len**。当字符串长度小于 1M 时，扩容都是加倍现有的空间，如果超过 1M，扩容时一次只会多扩 1M 的空间。需要注意的是字符串最大长度为 `512M`。

#### 链表（List）

**单键多值Redis** 

`链表`是简单的`字符串列表`，按照`插入顺序排序`。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。它的底层实际是个`双向链表`，对两端的操作性能很高，通过索引下标的操作中间的节点性能会较差。

<img src="https://oss.zhulinz.top//img/image-20220522112807853.png" alt="image-20220522112807853"/>

```tex
lpush/rpush <key><value1><value2><value3> ....	从左边/右边插入一个或多个值。 
lpop/rpop <key>									从左边/右边吐出一个值。值在键在，值光键亡。 
rpoplpush <key1><key2>							从<key1>列表右边吐出一个值，插到<key2>列表左边。 
lrange <key><start><stop>						按照索引下标获得元素(从左到右) 
lrange mylist 0 -1								0 左边第一个，-1 右边第一个，（0-1 表示获取所有） 
lindex <key><index>								按照索引下标获得元素(从左到右) 
llen <key>										获得列表长度 
linsert <key> before <value><newvalue>			在<value>的后面插入<newvalue>插入值 
lrem <key><n><value>			        		从左边删除 n 个 value(从左到右) 
lset<key><index><value>							将列表 key 下标为 index 的值替换成 value
```

##### 数据结构

List 的数据结构为`快速链表 quickList`。首先在列表元素较少的情况下会使用一块连续的内存存储，这个结构是 `ziplist`，也即是**压缩列表**。它将所有的元素紧挨着一起存储，分配的是一块连续的内存。当`数据量比较多`的时候才会改成` quicklist`。因为普通的链表需要的`附加指针空间太大`，`会比较浪费空间`。比如这个列表里存的只是 int 类型的数据，结构上还需要两个额外的指针` prev `和` next`。 

<img src="https://oss.zhulinz.top//img/image-20220522113324227.png" alt="image-20220522113324227"/>

Redis 将`链表`和` ziplist `结合起来组成了` quicklist`。也就是将多个 ziplist 使用`双向指针`串起来使用。这样既满足了`快速的插入删除性能`，又不会出现`太大的空间冗余`。

#### 集合（Set）

`Redis set `对外提供的功能与 list 类似是一个列表的功能，特殊之处在于` set `是可以**自动去重**的，当你需要存储一个`列表数据`，又不希望出现`重复数据`时，set 是一个很好的选择，并且 set 提供了`判断某个成员是否在一个 set 集合内的重要接口`，这个也是 list 所不能提供的。Redis 的` set `是` string `类型的`无序集合`。它底层其实是一个` value 为 null 的 hash 表`，所以`添加，删除，查找`的**复杂度都是** **O(1)**。一个算法，随着数据的增加，执行时间的长短，如果是 O(1)，数据增加，查找数据的时间不变。

```tex
sadd <key><value1><value2> ....			将一个或多个 member 元素加入到集合 key 中，已经存在的 member 元素将被忽略 
smembers <key>				           	取出该集合的所有值。 
sismember <key><value>			       	判断集合<key>是否为含有该<value>值，有 1，没有 0 
scard<key>			                   	返回该集合的元素个数。
srem <key><value1><value2> .... 	    删除集合中的某个元素。 
spop <key>				               	随机从该集合中吐出一个值。 
srandmember <key><n>		            随机从该集合中取出 n 个值。不会从集合中删除 。 
smove <source><destination>value		把集合中一个值从一个集合移动到另一个集合 
sinter <key1><key2>			      		返回两个集合的交集元素。 
sunion <key1><key2>			    		返回两个集合的并集元素。 
sdiff <key1><key2>						返回两个集合的差集元素(key1 中的，不包含 key2 中的)
```

##### 数据结构

Set 数据结构是 `dict 字典`，字典是用`哈希表`实现的。Java 中 HashSet 的内部实现使用的是 `HashMap`，只不过所有的` value 都指向同一个对象`。Redis 的 set 结构也是一样，它的内部也使用 hash 结构，所有的 value 都指向同一个内部值。

#### 哈希（Hash）

- `Redis hash `是一个`键值对集合`。 
- `Redis hash `是一个` string `类型的` field `和` value `的映射表，hash 特别适合用于存储对象。 
- 类似 Java 里面的` Map<String,Object> `。
- 用户 ID 为查找的 key，存储的 value 用户对象包含姓名，年龄，生日等信息，如果用普通的 key/value 结构来存储 

主要有以下 2 种存储方式：

<img src="https://oss.zhulinz.top//img/image-20220522113735993.png" alt="image-20220522113735993" width="45%" />

```tex
hset <key><field><value>			  	          	给<key>集合中的 <field>键赋值<value> 
hget <key1><field>					  		     	从<key1>集合<field>取出 value 
hmset <key1><field1><value1><field2><value2>...    	批量设置 hash 的值 
hexists<key1><field>				       		 	查看哈希表 key 中，给定域 field 是否存在。 
hkeys <key>						           	     	列出该 hash 集合的所有 field 
hvals <key>							             	列出该 hash 集合的所有 value 
hincrby <key><field><increment>				      	为哈希表 key 中的域 field 的值加上增量 1 -1 
hsetnx <key><field><value>						 	将哈希表 key 中的域 field 的值设置为 value ，当且仅当域 field 不存在 .
```

##### 数据结构

Hash 类型对应的数据结构是两种：`ziplist（压缩列表）`，`hashtable（哈希表）`。当`field-value `长度较短且个数较少时，使用` ziplist`，否则使用` hashtable`。

#### 有序集合Zset（sorted set）

Redis **有序集合 zset 与普通集合 set** 非常相似，是一个`没有重复元素的字符串集合`。不同之处是`有序集合的每个成员`都关联了一个**评分（score）**，这个评分（score）被用来按照从`最低分到最高分`的方式排序集合中的成员。集合的成员是唯一的，但是评分可用是重复的 。因为元素是`有序`的, 所以你也可以很快的根据评分（score）或者次序（position）来获取一个范围的元素。访问有序集合的中间元素也是非常快的,因此你能够使用有序集合作为一个没有重复成员的智能列表。

```tex
zadd <key><score1><value1><score2><value2>… 		将一个或多个 member 元素及其 score 值加入到有序集 key 当中。 
zrange <key><start><stop> [WITHSCORES] 	        	返回有序集 key 中，下标在<start><stop>之间的元素 带 WITHSCORES，可以让分数一起和值返回到结果集。 
zrangebyscore key minmax [withscores] [limit offset count] 				
返回有序集 key 中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员。 有序集成员按 score 值递增(从小到大)次序排列。 

zrevrangebyscore key maxmin [withscores] [limit offset count] 	同上，改为从大到小排列。
zincrby <key><increment><value> 		       					为元素的 score 加上增量 
zrem <key><value>			                   					删除该集合下，指定值的元素 
zcount <key><min><max>					      					统计该集合，分数区间内的元素个数 
zrank <key><value>							 					返回该值在集合中的排名，从 0 开始。
```

##### 数据结构

`SortedSet(zset) `是 Redis 提供的一个非常特别的数据结构，一方面它`等价于 Java的数据结构 Map<String, Double>`，可以给每一个元素 value 赋予一个**权重 score**，另一方面它又类似于` TreeSet`，内部的元素会按照`权重 score 进行排序`，可以得到每个元素的名次，还可以通过` score 的范围来获取元素的列表`。 

zset 底层使用了两个数据结构 

- `hash`，hash的作用就是**关联元素 value 和权重 score**，保障元素 value 的`唯一性`，可以通过元素 value 找到相应的 score 值。 
- `跳跃表`，跳跃表的目的`在于给元素 value 排序`，根据 score 的范围获取元素列表。

##### 跳跃表（跳表）

有序集合在生活中比较常见，例如根据成绩对学生排名，根据得分对玩家排名等。对于有序集合的底层实现，可以用数组、平衡树、链表等。数组不便元素的插入、删除；平衡树或红黑树虽然效率高但结构复杂；链表查询需要遍历所有效率低。Redis采用的是跳跃表。跳跃表效率堪比红黑树，实现远比红黑树简单。

2、实例

对比有序链表和跳跃表，从链表中查询出 51 

（1） 有序链表 

  要查找值为 51 的元素，需要从第一个元素开始依次查找、比较才能找到。共需要 6 次比较。 

（2） 跳跃表 

<img src="https://oss.zhulinz.top//img/image-20220522114511831.png" alt="image-20220522114511831" width="50%" />

- 从第 2 层开始，1 节点比 51 节点小，向后比较。21 节点比 51 节点小，继续向后比较，后面就是 NULL 了，所以从 21 节点向下到第 1 层 
- 在第 1 层，41 节点比 51 节点小，继续向后，61 节点比 51 节点大，所以从 41 向下 
- 在第 0 层，51 节点为要查找的节点，节点被找到，共查找 4 次。 
- 从此可以看出跳跃表比有序链表效率要高 

### 2.2、3种特殊类型

> **1、Bitmaps（位存储）**，即位图数据结构，都是操作二进制位来进行记录，只有0和1两个状态。

现代计算机用二进制（位） 作为信息的基础单位，1 个字节等于 8 位，例如“abc” 字符串是由 3 个字节组成，但实际在计算机存储时将其用二进制表示，“abc”分别对应的 ASCII 码分别是 97、 98、 99，对应的二进制分别是 01100001、01100010和 01100011，如下图 

<img src="https://oss.zhulinz.top//img/image-20220522184731379.png" alt="image-20220522184731379"/>

合理地使用操作位能够有效地提高内存使用率和开发效率。Redis 提供了 Bitmaps 这个“数据类型”可以实现对位的操作： 

- Bitmaps 本身不是一种数据类型， 实际上它就是字符串（key-value） ，但是它可以对字符串的位进行操作。 
- Bitmaps 单独提供了一套命令， 所以在 Redis 中使用 Bitmaps 和使用字符串的方法不太相同。 可以把 Bitmaps 想象成一个以位为单位的数组，数组的每个单元只能存储 0 和 1， 数组的下标在 Bitmaps 中叫做偏移量。

<img src="https://oss.zhulinz.top//img/image-20220522184824449.png" alt="image-20220522184824449"/>

```
setbit<key><offset><value>				设置 Bitmaps 中某个偏移量的值（0 或 1）
注： 
很多应用的用户 id 以一个指定数字（例如 10000） 开头， 直接将用户 id 和 Bitmaps 的偏移量对应势必会造成一定的浪费， 通常的做法是每次做 setbit 操作时将 用户 id 减去这个指定数字。 在第一次初始化 Bitmaps 时， 假如偏移量非常大， 那么整个初始化过程执行会 比较慢， 可能会造成 Redis 的阻塞。

getbit<key><offset>						获取 Bitmaps 中某个偏移量的值

bitcount<key>[start end] 				统计字符串从 start 字节到 end 字节比特值为 1 的数量
统计字符串被设置为 1 的 bit 数。一般情况下，给定的整个字符串都会被进行计数，通 过指定额外的 start 或 end 参数，可以让计数只在特定的位上进行。start 和 end 参数 的设置，都可以使用负数值：比如 -1 表示最后一个位，而 -2 表示倒数第二个位， start、end 是指 bit 组的字节的下标数，二者皆包含。

bitop and(or/not/xor) <destkey> [key…]
bitop 是一个复合操作， 它可以做多个 Bitmaps 的 and（交集） 、 or（并集） 、 not （非） 、 xor（异或） 操作并将结果保存在 destkey 中。
```

**用来解决什么问题？**

比如：统计用户信息，活跃、不活跃，登录、未登录，打卡、未打卡。`两个状态的，都可以使用Bitmaps`。

如果存储一年的打卡状态需要多少内存呢？ 365 天 = 365 bit 1字节 = 8bit 46 个字节左右！

**相关命令使用**

使用bitmap 来记录 周一到周日的打卡！ 周一：1 周二：0 周三：0 周四：1 ......

```sh
127.0.0.1:6379> setbit sign 0 1
(integer) 0
127.0.0.1:6379> setbit sign 1 1
(integer) 0
127.0.0.1:6379> setbit sign 2 0
(integer) 0
127.0.0.1:6379> setbit sign 3 1
(integer) 0
127.0.0.1:6379> setbit sign 4 0
(integer) 0
127.0.0.1:6379> setbit sign 5 0
(integer) 0
127.0.0.1:6379> setbit sign 6 1
(integer) 0
```

查看某一天是否有打卡！

```sh
127.0.0.1:6379> getbit sign 3
(integer) 1
127.0.0.1:6379> getbit sign 5
(integer) 0
```

统计操作，统计 打卡的天数！

```sh
127.0.0.1:6379> bitcount sign # 统计这周的打卡记录，就可以看到是否有全勤！
(integer) 3
```

> **2、HyperLogLog（基数统计）**

在工作当中，我们经常会遇到与统计相关的功能需求，比如统计网站 PV（PageView 页面访问量）,可以使用 Redis 的 incr、incrby 轻松实现。 但像 UV（UniqueVisitor，独立访客）、独立 IP 数、搜索记录数等需要去重和计数的问题如何解决？这种求集合中不重复元素个数的问题称为基数问题。 解决基数问题有很多种方案： 

- 数据存储在 MySQL 表中，使用 distinct count 计算不重复个数 
- 使用 Redis 提供的 hash、set、bitmaps 等数据结构来处理 

以上的方案结果精确，但随着数据不断增加，导致占用空间越来越大，对于非常大的数据集是不切实际的。能否能够降低一定的精度来平衡存储空间？Redis 推出了 HyperLogLog Redis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。 

在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。 

**什么是基数?** 

比如数据集 {1, 3, 5, 7, 5, 7, 8}， 那么这个数据集的基数集为 {1, 3, 5 ,7, 8}, 

基数(不重复元素)为 5。 基数估计就是在误差可接受的范围内，快速计算基数。

```sh
pfadd <key>< element> [element ...] 			    	添加指定元素到 HyperLogLog 中
执行命令后 HLL 估计的 近似基数发生变化，则返回 1，否则返回 0。
pfcount<key> [key ...] 						       		计算 HLL 的近似基数，可以计算多个 HLL，比如用 HLL 存储每 天的 UV，计算一周的 UV 可以使用 7 天的 UV 合并计算即可
pfmerge<destkey><sourcekey> [sourcekey ...] 			将一个或多个 HLL 合并后的结果存 储在另一个 HLL 中，比如每月活跃用户可以使用每天的活跃用户来合并计算可得
```

**HyperLogLogs基数统计用来解决什么问题？**

这个结构可以非常省内存的去统计各种计数，例如：注册IP数、每日访问IP数、页面实时UV、在线用户数、共同好友数等。

**优势体现？**

一个大型的网站，每天 IP 比如有 100 万，粗算一个 IP 消耗 15 字节，那么 100 万个 IP 就是 15M。而 HyperLogLog 在 Redis 中每个键占用的内容都是 12K，理论存储近似接近 2^64 个值，不管存储的内容是什么，它一个基于基数估算的算法，只能比较准确的估算出基数，可以使用少量固定的内存去存储并识别集合中的唯一元素。而且这个估算的基数并不一定准确，是一个带有 0.81% 标准错误的近似值（对于可以接受一定容错的业务场景，比如IP数统计，UV等，是可以忽略不计的）。

**相关命令**

```sh
127.0.0.1:6379> pfadd key1 a b c d e f g h i	# 创建第一组元素
(integer) 1
127.0.0.1:6379> pfcount key1					# 统计元素的基数数量
(integer) 9
127.0.0.1:6379> pfadd key2 c j k l m e g a		# 创建第二组元素
(integer) 1
127.0.0.1:6379> pfcount key2
(integer) 8
127.0.0.1:6379> pfmerge key3 key1 key2			# 合并两组：key1 key2 -> key3 并集
OK
127.0.0.1:6379> pfcount key3
(integer) 13
```

> **3、geospatial (地理位置)**

### 2.3、Stream类型

[参考](https://www.pdai.tech/md/db/nosql-redis/db-redis-data-type-stream.html)

### 2.4、对象机制

### 2.5、底层数据结构

> #### 1、SDS简单动态字符串

![image-20220802083018221](https://oss.zhulinz.top//img/202208020830604.png)

- 字符串长度处理：Redis获取字符串长度，时间复杂度为O(1)，而C语言中，需要从头开始遍历，复杂度为O（n）;
- 空间预分配：字符串修改越频繁的话，内存分配越频繁，就会消耗性能，而SDS修改和空间扩充，会额外分配未使用的空间，减少性能损耗。
- 惰性空间释放：SDS 缩短时，不是回收多余的内存空间，而是free记录下多余的空间，后续有变更，直接使用free中记录的空间，减少分配。

> #### 2、字典

Redis 作为 K-V 型内存数据库，所有的键值就是用字典来存储。字典就是哈希表，比如HashMap，通过key就可以直接获取到对应的value。而哈希表的特性，在O（1）时间复杂度就可以获得对应的值。

> #### 3、跳跃表

![image-20220802083054382](https://oss.zhulinz.top//img/202208020830785.png)

- 跳跃表是Redis特有的数据结构，就是在链表的基础上，增加多级索引提升查找效率。
- 跳跃表支持平均 O（logN）,最坏 O（N）复杂度的节点查找，还可以通过顺序性操作批量处理节点。

## 三、持久化机制

> **为什么需要持久化？**

Redis是个基于内存的数据库，服务一旦宕机，内存中的数据就会全部丢失。通常的解决方案是从后端数据库中恢复这些数据，但后端数据库有性能瓶颈，如果是大数据量的恢复。

- 将对数据库带来巨大的压力
- 数据库的性能不如Redis，导致程序响应慢。

对于Redis来说，实现数据的持久化，应该避免从后端数据库中恢复数据，是至关重要的。

### 3.1、RDB持久化

RDB持久化，是指在`指定的时间间隔内`，`执行指定次数的写操作`，将`内存中的数据集快照写入磁盘中`，它是Redis默认的持久化方式。执行完操作后，在指定目录下会生成一个dump.rdb文件，Redis 重启的时候，通过加载dump.rdb文件来恢复数据。RDB触发机制主要有以下几种：

> **1、触发方式**

![RDB触发机制](https://oss.zhulinz.top//img/202208020836500.png)

**手动触发**

- **save命令：**阻塞当前Redis服务器，直到RDB过程完成为止，对于内存比较大的实例会造成长时间`阻塞`，不建议线上环境使用。
- **bgsave命令：**Redis进程执行` fork 操作创建子进程`，RDB持久化过程由子进程负责，完成后自动结束。阻塞只发生在 fork 阶段，一般时间很短。

具体流程如下：

1. redis客户端`执行bgsave命令`或者`自动触发bgsave命令`。
2. 主进程`判断当前是否存在正在执行的子进程`，如果存在，则直接返回。
3. 如果不存在正在执行的子进程，那么就 fork 一个新的子进程进行持久化数据，`fork 过程是阻塞的`，fork 操作完后主进程即可执行其他操作。
4. 子进程先将数据写入到临时的 rdb 文件，待快照数据写入完成后再替换旧的 rdb 文件。
5. 同时发送信号给主进程，通知主进程 rdb 持久化完成，主进程更新相关的统计信息。

**自动触发**

- redis.conf 中配置` save m n`，即在m秒内有n次修改时，自动触发 bgsave 生产 rdb 文件。
- 主从复制时，从节点要从主节点进行`全量复制`时也会`触发 bgsave 操作`，生产当时的快照发送到从节点。
- 执行` debug reload `命令重写加载redis时也会`触发 bgsave 操作`。
- 默认情况下执行` shutdown `命令时，如果没有开启 AOF 持久化，也会触发 bgsave 操作。

> **2、备份是如何执行的？**

Redis 会`单独创建（fork）一个子进程来进行持久化`，会先将数据写入到 一个**临时文件**中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。 整个过程中，主进程是`不进行任何 IO 操作的`，这就`确保了极高的性能 `，如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那 RDB 方式要比 AOF 方式更加的高效。RDB的缺点**是最后一次持久化后的数据可能丢失**（最后一次持久化之后，服务器宕机或崩溃，在此次持久化之后的数据就会丢失）。

> **3、Fork创建子进程**

- Fork 的作用是`复制一个与当前进程一样的进程`。新进程的`所有数据（变量、环境变量、程序计数器等）`数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程。
- 在 `Linux`程序中，fork() 会产生一个和父进程完全相同的子进程，但子进程在此后多会 exec 系统调用，出于效率考虑，Linux 中引入了“**写时复制技术**” 。
- **一般情况父进程和子进程会共用同一段物理内存**，只有进程空间的各段的内容要发生变化时，才会将父进程的内容复制一份给子进程。

![image-20220731150728004](https://oss.zhulinz.top//img/202207311507584.png)

> **4、由于生产环境中我们为Redis开辟的内存区域都比较大（例如6GB），那么将内存中的数据同步到硬盘的过程可能就会持续比较长的时间，而实际情况是这段时间Redis服务一般都会收到数据写操作请求。那么如何保证数据一致性呢？**

RDB中的核心思路是Copy-on-Write（写时复制），来保证在进行快照操作的这段时间，需要压缩写入磁盘上的数据在内存中不会发送变化。在正常的快照操作中，一方面Redis主进程会 fork 一个新的快照进程专门来做这个事情，这样保证了Redis服务不会停止对客户端包括写请求在内的任何响应。另一方面这段时间内发生的数据变化会以副本的方式存放在另一个新的内存区域里，待快照操作结束后才会同步到原来的内存区域里。

举个例子：如果主线程对这些数据也都是读操作（例如图中的键值对 A），那么，主线程和 bgsave 子进程相互不影响。但是，如果主线程要修改一块数据（例如图中的键值对 C），那么，这块数据就会被复制一份，生成该数据的副本。然后，bgsave 子进程会把这个副本数据写入 RDB 文件，而在这个过程中，主线程仍然可以直接修改原来的数据。

![image-20220731153014377](https://oss.zhulinz.top//img/202207311530220.png)

> **5、在进行快照操作的这段时间，如果发生服务崩溃怎么办？**

在没有将数据全部写入到磁盘前，这次快照操作都不算成功。如果出现了服务器崩溃的情况，将会以上一次完整的RDB快照文件作为恢复内存数据的参考。在快照操作过程中不能影响上一次的备份数据。Redis服务会在磁盘上创建一个临时文件进行数据操作，待操作成功后才会用这个临时文件替换掉上一次的备份。

> **6、可以每秒做一次快照吗？**

连续的快照会使服务器发生宕机时，数据丢失的少些。但频繁的快照，会带来两方面的开销：

1. 一方面，频繁将全量数据写入磁盘，会给磁盘带来很大压力多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。
2. 另一方面，bgsave 子进程需要通过 fork 操作从主进程创建出来。虽然，子进程在创建后不会再阻塞主进程。但是 **fork 这个创建过程本身会阻塞主进程**。且主进程的内存越大，阻塞时间越长。如果频繁 fork 出 bgsave 子进程，就会`频繁阻塞主进程`了。

> **7、RDB的优缺点**

**优点：**

- 适合大规模的数据恢复 
- 对数据完整性和一致性要求不高更适合使用 
- 节省磁盘空间 
- 恢复速度快

<img src="https://oss.zhulinz.top//img/image-20220524000316624.png" alt="image-20220524000316624" width="45%" />

**缺点：**

- Fork 的时候，内存中的数据被克隆了一份，大致 2 倍的膨胀性需要考虑 
- 虽然 Redis 在 fork 时使用了**写时拷贝技术**，但是如果数据庞大时还是比较消耗性能。 
- 在备份周期在一定间隔时间做一次备份，所以如果 Redis 意外 down 掉的话，就会丢失最后一次快照后的所有修改。 

### 3.2、AOF持久化

> Redis是`“写后“日志`，Redis先执行命令，把数据写入内存，然后才记录日志。日志里记录的是Redis收到的每一条命令，这些命令是以文本形式保存的。PS：大多数的数据库采用的是`写前日志（WAL）`。例如MySQL，通过写前日志和两阶段提交，实现数据和逻辑的一致性。

是指`所有的命令行记录`以Redis命令请求协议的格式`完全持久化存储`，保存为AOF文件。Redis在执行完一条写操作命令后，就会把该命令以追加的命令写入到一个文件里，然后Redis重启时，会读取该文件记录的命令，再以`逐一执行命令的方式`来进行数据恢复。

![image-20220725162508622](https://oss.zhulinz.top//img/202207251639720.png)

**优点：**

- 数据安全，`AOF持久化`可以配置`appendfsync`属性，有`always`，每进行一次命令操作就记录到AOF文件中一次。
- 通过append模式写文件，即使途中服务器宕机，可以通过`redis-check-aof`工具解决`数据一致性问题`。
- AOF机制的`rewrite`模式。AOF文件没被rewrite之前（文件过大时会对命令进行合并重写），可以删除其中的某些命令（比如误操作的flushall）

**缺点：**

- AOF文件比RDB文件大，且恢复速度慢。
- 数据集大的时候，比RDB启动效率低。

> **1、为什么先执行命令，再把数据写入日志？（写后日志）**

- **避免额外的检查开销：**先执行命令，可以检查命令语法是否有错误，有错误将命令执行失败也不会写入日志中。避免了在使用日志恢复数据的时候，命令执行失败。
- **不会阻塞当前写操作命令的执行：**因为写操作命令执行成功后，才会将命令记录到日志中。

**风险也有**

- **数据可能会丢失：**执行写操作命令和记录日志是两个过程，在Redis还没将命令写入到硬盘时，服务器发生宕机了，就会有数据丢失的风险。
- **可能阻塞其他操作：**由于写操作命令执行成功后才记录到AOF日志，所以不会阻塞当前命令的执行。但是因为AOF日志也是在主线程中执行，所以将日志文件写入磁盘的 时候，可能会阻塞后续的操作无法执行。

> **2、AOF的写回策略**

AOF日志记录Redis的每个写命令，步骤为：命令追加（append）、文件写入（write）和文件同步（sync）；

1. **命令追加：**Redis 执行完`写操作命令`后，会将命令追加到` server.aof_buf 缓冲区`；
2. **文件写入和同步：**然后通过` write() 系统`调用，将` aof_buf 缓冲区`的数据写入到 AOF 文件，此时数据并没有写入到硬盘，而是拷贝到了`内核缓冲区 page cache`，等待内核将数据写入硬盘；
3. 具体内核缓冲区的数据什么时候写入到硬盘，由内核决定。

<img src="https://oss.zhulinz.top//img/202207251639896.png" alt="4eeef4dd1bedd2ffe0b84d4eaa0dbdea" style="width:33%;" />

**写回策略**

Redis 提供了 3 种写回硬盘的策略，控制的就是上面说的第三步的过程。 在 Redis.conf 配置文件中的 appendfsync 配置项可以有以下 3 种参数可填：

- **Always**，这个单词的意思是「总是」，所以它的意思是每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；
- **Everysec**，这个单词的意思是「每秒」，所以它的意思是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；
- **No**，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。

![image-20220725163405740](https://oss.zhulinz.top//img/202207251639746.png)

> **3、AOF日志过大，会触发什么机制？**（重写机制）

AOF 日志是一个文件，随着执行的写操作命令越来越多，文件的大小会越来越大。 如果当 AOF 日志文件过大就会带来性能问题，比如重启 Redis 后，需要读 AOF 文件的内容以恢复数据，如果文件过大，整个恢复的过程就会很慢。所以，Redis 为了避免 AOF 文件越写越大，提供了 **AOF 重写机制**，当 AOF 文件的`大小超过所设定的阈值后`，Redis 就会启用 AOF 重写机制，来`压缩 AOF 文件`。

**AOF 重写机制**是在重写时，读取当前数据库中的所有`键值对`，然后将`每一个键值对用一条命令`记录到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。

举个例子，在没有使用重写机制前，假设前后执行了「*set name xiaolin*」和「*set name xiaolincoding*」这两个命令的话，就会将这两个命令记录到 AOF 文件。

![image-20220725163502942](https://oss.zhulinz.top//img/202207251639852.png)

但是**在使用重写机制后，就会读取 name 最新的 value（键值对） ，然后用一条 「set name xiaolincoding」命令记录到新的 AOF 文件**，之前的第一个命令就没有必要记录了，因为它属于「历史」命令，没有作用了。这样一来，一个键值对在重写日志中只用一条命令就行了。

重写工作完成后，就会将新的 AOF 文件覆盖现有的 AOF 文件，这就相当于压缩了 AOF 文件，使得 AOF 文件体积变小了。

>  **4、重写AOF日志的过程是怎样的？**

Redis 的**重写 AOF 过程是由后台子进程` bgrewriteaof `来完成的**，这么做可以达到两个好处：

- 子进程进行 AOF 重写期间，主进程可以继续处理命令请求，从而`避免阻塞主进程`；
- **子进程带有主进程的数据副本**，这里使用子进程而不是线程，因为如果是使用线程，多线程之间会共享内存，那么在修改共享内存数据的时候，需要通过加锁来保证数据的安全，而这样就会降低性能。而使用子进程，创建子进程时，父子进程是共享内存数据的，不过这个共享的内存只能以只读的方式，而当父子进程任意一方修改了该共享内存，就会发生`「写时复制」`，于是父子进程就有了独立的数据副本，就不用加锁来保证数据安全。

触发重写机制后，主进程就会创建重写 AOF 的子进程，此时父子进程共享物理内存，重写子进程只会对这个内存进行`只读`，重写 AOF 子进程会读取数据库里的所有数据，并逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志（新的 AOF 文件）。

> **5、但是重写过程中，主进程依然可以正常处理命令**，那问题来了，重写 AOF 日志过程中，如果主进程修改了已经存在 key-value，那么会发生写时复制，此时这个 key-value 数据在子进程的内存数据就跟主进程的内存数据不一致了，这时要怎么办呢？

为了解决这种数据不一致问题（由于写时复制，键值对数据在子进程的内存数据与主进程的内存数据不一致了），Redis 设置了一个 **AOF 重写缓冲区**，这个缓冲区在创建 bgrewriteaof 子进程之后开始使用。

在重写 AOF 期间，当 Redis 执行完一个写命令之后，它会**同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」**。

![image-20220725164018683](https://oss.zhulinz.top//img/202207251640869.png)

也就是说，在 bgrewriteaof 子进程执行 AOF 重写期间，主进程需要执行以下三个工作:

- 执行客户端发来的命令；
- 将执行后的写命令追加到 「AOF 缓冲区」；
- 将执行后的写命令追加到 「AOF 重写缓冲区」；

当子进程完成 AOF 重写工作（*扫描数据库中所有数据，逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志*）后，会向主进程发送一条信号，信号是进程间通讯的一种方式，且是异步的。

主进程收到该信号后，会调用一个信号处理函数，该函数主要做以下工作：

- 将 AOF 重写缓冲区中的所有内容追加到新的 AOF 的文件中，使得新旧两个 AOF 文件所保存的数据库状态一致；
- 新的 AOF 的文件进行改名，覆盖现有的 AOF 文件。

信号函数执行完后，主进程就可以继续像往常一样处理命令了。

### 3.3、混合持久化机制

RDB的优点是`数据恢复速度快`，但是执行快照记录的`频率不好把握`。频率太低，会损失较多数据（未及时执行快照，而服务器宕机）。频率太快，就会影响性能；AOF优点是丢失数据少，但是数据恢复不快。

为了集成两者的优点，Redis4.0提出了混合使用**AOF日志和内存快照**（混合持久化），既保证了Redis重启速度，又降低了数据丢失风险。

混合持久化工作在**AOF日志重写过程中**，在AOF重写日志时，fork() 出来的重写子进程会先将**与主线程共享的内存数据以RDB方式写入到AOF文件中**，然后主线程处理的操作命令会被记录在`重写缓冲区`里，重写缓冲区里的**增量命令会以AOF方式写入到AOF文件**，写入完成后通知主进程将新的含有RDB格式和AOF格式的AOF文件替换旧的AOF文件。使用了混合持久化的AOF文件，前半部分是`RDB格式的全量数据`，后半部分是`AOF格式的增量数据`。

![image-20220725234807813](https://oss.zhulinz.top//img/202207260000446.png)

好处在于，重启Redis加载数据的时候，由于前半部分是RDB内容，加载的速度会很快。加载完RDB的内容后，才会加载后半部分的AOF内容（Redis后台子进程重写AOF期间，主线程处理的操作命令），可以使得数据更少的丢失。

**混合持久化的优点：**结合了RDB和AOF持久化的优点，开头为RDB的格式，使得Redis可以更快的启动，同时结合了AOF的优点，可以减少损失更多数据的风险。

**混合持久化的缺点：**AOF文件中添加了RDB格式的内容，使得AOF文件的可读性变得很差；兼容性差，混合持久化的方式只适用于Redis4.0版本之后。

> **1、从持久化中恢复数据**

![image-20220731161525752](https://oss.zhulinz.top//img/202207311615450.png)

1. redis重启时判断是否开启aof，如果开启了aof，那么就优先加载aof文件；
2. 如果aof存在，那么就去加载aof文件，加载成功的话redis重启成功，如果aof文件加载失败，那么会打印日志表示启动失败，此时可以去修复aof文件后重新启动；
3. 若aof文件不存在，那么redis就会转而去加载rdb文件，如果rdb文件不存在，redis直接启动成功；
4. 如果rdb文件存在就会去加载rdb文件恢复数据，如加载失败则打印日志提示启动失败，如加载成功，那么redis重启成功，且使用rdb文件恢复数据；

## 四、Redis的发布与订阅

Redis 发布订阅 (pub/sub) 是一种**消息通信模式**：`发送者 (pub) 发送消息`，`订阅者(sub) 接收消息`。Redis 客户端可以订阅任意数量的频道。 

客户端可以订阅频道如下图 

<img src="https://oss.zhulinz.top//img/image-20220522121140826.png" alt="image-20220522121140826" width="40%" />

当给这个频道发布消息后，消息就会发送给订阅的客户端

<img src="https://oss.zhulinz.top//img/image-20220522121201473.png" alt="image-20220522121201473" width="40%" />

```sh
SUBSCRIBE channel1		 	客户端订阅 channel1
publish channel1 hello	 	另一个客户端，给 channel1 发布消息 hello
发布的消息没有持久化，如果在订阅的客户端收不到 hello，只能收到订阅后发布 的消息
```

### 4.1、基于频道（Channel）的发布与订阅

”发布/订阅“模式包含两种角色，分别是发布者和订阅者。发布则可以向指定的频道（channel）发送消息；订阅者可以订阅一个或者多个频道（channel）。所有订阅此频道的订阅者都会收到消息。

![image-20220731161845435](https://oss.zhulinz.top//img/202207311618183.png)

> **1、发布者发布消息**

发布则发布消息的命令是 publish，用法是 publish channel message。

```sh
127.0.0.1:6379> publish channel:1 hi
(integer) 1
```

返回值表示接收这条消息的订阅者数量。发出的消息不会被持久化。也就是有客户端订阅channel:1后只能接收到后续发布到该频道的消息，之前的就接收不到了。

> **2、订阅者订阅频道**

订阅频道的命令是 subscribe，可以同时订阅多个频道。用法是 subscribe channel1 [channel2...]。例如新开一个客户端订阅上面频道，则不会收到消息，因为不会收到订阅之前就发布到该频道的消息。

```sh
127.0.0.1:6379> subscribe channel:1
Reading messages... (press Ctrl-C to quit)
1) "subscribe" // 消息类型
2) "channel:1" // 频道
3) "hi" // 消息内容
```

- subscribe。表示订阅成功的反馈信息。第二个值是订阅成功的频道名称，第三个是当前客户端订阅的频道数量。
- message。表示接收到的消息，第二个值表示产生消息的频道名称，第三个值是消息的内容。
- unsubscribe。表示成功取消订阅某个频道。第二个值是对应的频道名称，第三个值是当前客户端订阅的频道数量，当此值为0时客户端会退出订阅状态，之后就可以执行其他非"发布/订阅"模式的命令了

### 4.2、基于模式（pattern）的发布与订阅

如果有某个/某些模式和这个频道匹配的话，那么所有订阅这个/这些频道的客户端也同样会收到信息。

下图展示了一个带有频道和模式的例子， 其中` tweet.shop.* `模式匹配了` tweet.shop.kindle 频道`和` tweet.shop.ipad 频道`， 并且有不同的客户端分别订阅它们三个：

![image-20220731162833246](https://oss.zhulinz.top//img/202207311628894.png)

当有信息发送到 tweet.shop.kindle 频道时， 信息除了发送给 clientX 和 clientY 之外， 还会发送给订阅 tweet.shop.* 模式的 client123 和 client256 ：

![image-20220731162909647](https://oss.zhulinz.top//img/202207311629291.png)

另一方面， 如果接收到信息的是频道 tweet.shop.ipad ， 那么 client123 和 client256 同样会收到信息：

![image-20220731162931862](https://oss.zhulinz.top//img/202207311629917.png)

## 五、事件机制

Redis中的事件驱动库只关注网络IO，以及定时器。

- **文件事件：**用于处理 Redis 服务器和客户端之间的网路IO。
- **时间事件：**Redis服务器中的一些操作（比如 serveCron函数）需要在给定的时间点执行，而时间事件就是处理这类定时操作的。

事件驱动库的代码主要是在`src/ae.c`中实现的，其实意图如下：

![image-20220731170644771](https://oss.zhulinz.top//img/202207311706162.png)

`aeEventLoop`是整个事件驱动的核心，它管理着文件事件表和时间事件列表，不断地循环处理着就绪的文件事件和到期的时间事件。

### 5.1、文件事件

Redis是基于Reactor模式开发了自己的网络事件处理器，也就是文件事件处理器。文件事件处理器使用**IO多路复用技术**，同时监听多个套接字，并为套接字关联不同的事件处理函数。当套接字的可读或者可写事件触发时，就会调用相应的事件处理函数。

> **1、为什么单线程的Redis能那么快？**

Redis的瓶颈`主要在IO而不是CPU`，所以为了省开发量，在6.0版本前是单线程模型；其次，Redis 是单线程主要是指 **Redis 的网络 IO 和键值对读写是由一个线程来完成的**，这也是 Redis 对外提供键值存储服务的主要流程。（但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的）。

Redis 采用了多路复用机制使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率。

> **2、Redis事件响应框架ae_event及文件事件处理器**

Redis 使用的IO多路复用技术主要有：`select`、`epoll`、`evport`和`kqueue`等。每个IO多路复用函数库在 Redis 源码中都对应一个单独的文件，比如`ae_select.c`，`ae_epoll.c`， `ae_kqueue.c`等。Redis 会根据不同的操作系统，按照不同的优先级选择多路复用技术。事件响应框架一般都采用该架构，比如 netty 和 libevent。

![image-20220731171228046](https://oss.zhulinz.top//img/202207311712122.png)

文件事件处理器主要有四个组成部分，分别是套接字、I/O多路复用程序、文件事件分派器以及事件处理器。

![image-20220731171329477](https://oss.zhulinz.top//img/202207311713215.png)

文件事件是对套接字操作的抽象，每当一个套接字准备好执行 `accept`、`read`、`write`和 `close` 等操作时，就会产生一个文件事件。因为 Redis 通常会连接多个套接字，所以多个文件事件有可能并发的出现。

I/O多路复用程序负责监听多个套接字，并向文件事件派发器传递那些产生了事件的套接字。

尽管多个文件事件可能会并发地出现，但I/O多路复用程序总是会将所有产生的套接字都放到同一个队列(也就是后文中描述的aeEventLoop的fired就绪事件表)里边，然后文件事件处理器会以有序、同步、单个套接字的方式处理该队列中的套接字，也就是处理就绪的文件事件

![image-20220731171352138](https://oss.zhulinz.top//img/202207311713396.png)

所以，一次 Redis 客户端与服务器进行连接并且发送命令的过程如上图所示。

- 客户端向服务端发起**建立 socket 连接的请求**，那么监听套接字将产生 AE_READABLE 事件，触发连接应答处理器执行。处理器会对客户端的连接请求
- 进行**应答**，然后创建客户端套接字，以及客户端状态，并将客户端套接字的 AE_READABLE 事件与命令请求处理器关联。
- 客户端建立连接后，向服务器**发送命令**，那么客户端套接字将产生 AE_READABLE 事件，触发命令请求处理器执行，处理器读取客户端命令，然后传递给相关程序去执行。
- **执行命令获得相应的命令回复**，为了将命令回复传递给客户端，服务器将客户端套接字的 AE_WRITEABLE 事件与命令回复处理器关联。当客户端试图读取命令回复时，客户端套接字产生 AE_WRITEABLE 事件，触发命令回复处理器将命令回复全部写入到套接字中。

> **3、IO多路复用模型**

在 Redis 只运行单线程的情况下，**该机制允许内核中，同时存在多个监听套接字和已连接套接字**。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。

下图就是基于多路复用的 Redis IO 模型。图中的多个 FD 就是刚才所说的多个套接字。Redis 网络框架调用 epoll 机制，让内核监听这些套接字。此时，Redis 线程不会阻塞在某一个特定的监听或已连接套接字上，也就是说，不会阻塞在某一个特定的客户端请求处理上。正因为此，Redis 可以同时和多个客户端连接并处理请求，从而提升并发性。

![image-20220731171516738](https://oss.zhulinz.top//img/202207311715360.png)

基于多路复用的Redis高性能IO模型为了在请求到达时能通知到 Redis 线程，select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。那么，回调机制是怎么工作的呢？

其实，select/epoll 一旦监测到 FD 上有请求到达时，就会触发相应的事件。这些事件会被放进一个事件队列，Redis 单线程对该事件队列不断进行处理。这样一来，Redis 无需一直轮询是否有请求实际发生，这就可以避免造成 CPU 资源浪费。同时，Redis 在对事件队列中的事件进行处理时，会调用相应的处理函数，这就实现了基于事件的回调。因为 Redis 一直在对事件队列进行处理，所以能及时响应客户端请求，提升 Redis 的响应性能。

### 5.2、时间事件

- **定时事件**：让一段程序在指定的时间之后执行一次。
- **周期性事件**：让一段程序每隔指定时间就执行一次。

Redis的时间事件的具体定义结构：

```c
typedef struct aeTimeEvent {
    /* 全局唯一ID */
    long long id; /* time event identifier. */
    /* 秒精确的UNIX时间戳，记录时间事件到达的时间*/
    long when_sec; /* seconds */
    /* 毫秒精确的UNIX时间戳，记录时间事件到达的时间*/
    long when_ms; /* milliseconds */
    /* 时间处理器 */
    aeTimeProc *timeProc;
    /* 事件结束回调函数，析构一些资源*/
    aeEventFinalizerProc *finalizerProc;
    /* 私有数据 */
    void *clientData;
    /* 前驱节点 */
    struct aeTimeEvent *prev;
    /* 后继节点 */
    struct aeTimeEvent *next;
} aeTimeEvent;

```

一个时间事件是定时事件还是周期性事件取决于时间处理器的返回值：

- 如果返回值是 `AE_NOMORE`，那么这个事件是一个定时事件，该事件在达到后删除，之后不会再重复。
- 如果返回值是非 `AE_NOMORE` 的值，那么这个事件为周期性事件，当一个时间事件到达后，服务器会根据时间处理器的返回值，对时间事件的 when 属性进行更新，让这个事件在一段时间后再次达到。

![image-20220731171722492](https://oss.zhulinz.top//img/202207311717911.png)

服务器所有的时间事件都放在一个无序链表中，每当时间事件执行器运行时，它就遍历整个链表，查找所有已到达的时间事件，并调用相应的事件处理器。正常模式下的Redis服务器只使用serverCron一个时间事件，而在benchmark模式下，服务器也只使用两个时间事件，所以不影响事件执行的性能。

## 六、Redis事务

### 6.1、什么是Redis事务？

Redis事务的**本质是一组命令的集合**。事务`支持一次执行多个命令`，一个事务中的所有命令都会被`序列化`。在事务执行过程中，会按照`顺序串行执行队列中的命令`，其他客户端提交的命令`请求不会插入到事务执行命令序列中`。

Redis 事务是一个单独的**隔离操作**：事务中的所有命令都会**序列化**、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 

Redis 事务的主要作用**就是串联多个命令防止别的命令插队**。

### 6.2、Redis事务相关命令和使用

> MULTI 、 EXEC 、 DISCARD 和 WATCH 是 Redis 事务相关的命令。

- MULTI ：开启事务，redis会将后续的命令逐个放入队列中，然后使用EXEC命令来原子化执行这个命令系列。
- EXEC：执行事务中的所有操作命令。
- DISCARD：取消事务，放弃执行事务块中的所有命令。
- WATCH：监视一个或多个key,如果事务在执行前，这个key(或多个key)被其他命令修改，则事务被中断，不会执行事务中的任何命令。
- UNWATCH：取消WATCH对所有key的监视。

**Multi命令：**输入的命令都会依次进入命令队列中，不会执行，直到输入`exec`后才会依次执行命令。组队过程可通过`discard`放弃组队。

<img src="https://oss.zhulinz.top//img/image-20220523234928318.png" alt="image-20220523234928318"/>

> **标准的事务执行**

给k1、k2分别赋值，在事务中修改k1、k2，执行事务后，查看k1、k2值都被修改。

```sh
127.0.0.1:6379> set k1 v1
OK
127.0.0.1:6379> set k2 v2
OK
127.0.0.1:6379> MULTI
OK
127.0.0.1:6379> set k1 11
QUEUED
127.0.0.1:6379> set k2 22
QUEUED
127.0.0.1:6379> EXEC
1) OK
2) OK
127.0.0.1:6379> get k1
"11"
127.0.0.1:6379> get k2
"22"
```

> **事务取消**

```sh
127.0.0.1:6379> MULTI
OK
127.0.0.1:6379> set k1 33
QUEUED
127.0.0.1:6379> set k2 34
QUEUED
127.0.0.1:6379> DISCARD
OK
```

> **事务出现错误的处理**

**错误处理**

- 组队中某个命令出现报告错误，执行时整个的所有队列都会被取消。
- 执行中某个命令出现错误，则只有错的命令不会执行，其余命令正常执行，事务并不会回滚。

**语法错误（编译器错误）**

在开启事务后，修改k1值为11，k2值为22，但k2语法错误，最终导致事务提交失败，k1、k2保留原值。

```sh
127.0.0.1:6379> set k1 v1
OK
127.0.0.1:6379> set k2 v2
OK
127.0.0.1:6379> MULTI
OK
127.0.0.1:6379> set k1 11
QUEUED
127.0.0.1:6379> sets k2 22
(error) ERR unknown command `sets`, with args beginning with: `k2`, `22`, 
127.0.0.1:6379> exec
(error) EXECABORT Transaction discarded because of previous errors.
127.0.0.1:6379> get k1
"v1"
127.0.0.1:6379> get k2
"v2"
```

**Redis类型错误（运行时错误）**

在开启事务后，修改k1值为11，k2值为22，但将k2的类型作为List，在运行时检测类型错误，最终导致事务提交失败，此时事务并没有回滚，而是跳过错误命令继续执行， 结果k1值改变、k2保留原值

```sh
127.0.0.1:6379> set k1 v1
OK
127.0.0.1:6379> set k1 v2
OK
127.0.0.1:6379> MULTI
OK
127.0.0.1:6379> set k1 11
QUEUED
127.0.0.1:6379> lpush k2 22
QUEUED
127.0.0.1:6379> EXEC
1) OK
2) (error) WRONGTYPE Operation against a key holding the wrong kind of value
127.0.0.1:6379> get k1
"11"
127.0.0.1:6379> get k2
"v2"
```

### 6.3、锁机制

**悲观锁**

定义：每次去拿数据时都认为别人会修改，所以每次拿数据时都会给数据上锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，**读锁**，**写锁**等，都是在做操作之前先上锁。

**乐观锁**

定义：每次拿数据时都认为别人不会修改，因此不会上锁，只是在更新的时候会判断在此期间数据有没有更新，可用使用版本号等机制。**乐观锁适用于多读的应用类型，这样可以提高吞吐量。Redis 就是利用这种 check-and-set 机制实现事务的。**

**WATCH** **key** **[key ...]** 

在执行 multi 之前，先执行 watch key1 [key2],可以监视一个(或多个) key ，如果在事务**执行之前这个****(****或这些****) key** **被其他命令所改动，那么事务将被打断。**

**unwatch**

取消 WATCH 命令对所有 key 的监视。如果在执行 WATCH 命令之后，EXEC 命令或 DISCARD 命令先被执行了的话，那么就不需要再执行 UNWATCH 了。

### 6.4、Redis事务的ACID

> **原子性**

事务根据multi与exec配合使用，就可以保证多个操作都完成。但是如果事务执行过程出现错误了错误，redis会怎么处理：

1. 在执行 EXEC 命令前，客户端发送的操作命令本身就有错误（比如语法错误，使用了不存在的命令），这时在命令入队时就被 Redis 实例判断出来了。redis会在客户端发送exec命令后，Redis 就会拒绝执行所有提交的命令操作，返回事务失败的结果。这样一来，事务中的所有命令都不会再被执行了，保证了原子性。
2. 事务操作入队时，命令和操作的数据类型不匹配，但 Redis 实例没有检查出错误。在执行完 EXEC 命令以后，Redis 实际执行这些事务操作时，就会报错。Redis 会对错误命令报错，但还是会把正确的命令执行完。在这种情况下，事务的原子性就无法得到保证了。redis没有提供回滚机制，但是 Redis 提供了 DISCARD 命令，但是，这个命令只能用来主动放弃事务执行，把暂存的命令队列清空，起不到回滚的效果（即该命令只有在执行exec命令前有效）。
3. 在执行事务的 EXEC 命令时，Redis 实例发生了故障，导致事务执行失败。在这种情况下，如果redis实例，开启了 AOF 日志，只会有部分的事务操作被记录到 AOF 日志中。此时需要使用 redis-check-aof 工具检查 AOF 日志文件，这个工具可以把未完成的事务操作从 AOF 文件中去除。这样一的话，使用 AOF 恢复实例后，事务操作不会再被执行，从而保证了原子性。如果没有开启aof，那么就无法保证原子性。

> **一致性**

1. 命令入队时报错：在这种情况下，事务本身就会被放弃执行，所以可以保证数据库的一致性。
2. 命令入队时没报错，实际执行时报错：有错误的命令不会被执行，正确的命令可以正常执行，也不会改变数据库的一致性。
3. EXEC 命令执行时实例发生故障：这种情况下，需要考虑redis是否开启了持久化策略，如果没有开启rdb与aof，实例故障重启后，数据都没有了，数据库是一致的。

**使用了 AOF 日志**

1. 事务操作没有记录到AOF日志时：实例就发生了故障，那么，使用 AOF 日志恢复的数据库数据是一致的。
2. 部分操作被记录到了AOF日志时：可以使用 redis-check-aof 清除事务中已经完成的操作，数据库恢复后也是一致的。

> **隔离性**

事务的隔离性保证，会受到和事务一起执行的并发操作的影响，事务执行又可以分成（EXEC 命令执行前）和（EXEC 命令执行后）两个阶段

1. 并发操作在 EXEC 命令前执行，此时，隔离性的保证要使用 WATCH 机制来实现，否则隔离性无法保证；

2. 并发操作在 EXEC 命令后执行，此时，隔离性可以保证。

   而WATCH 机制的作用是，在事务执行前，监控一个或多个键的值变化情况，当事务调用 EXEC 命令执行时，WATCH 机制会先检查监控的键是否被其它客户端修改了。如果修改了，就放弃自己的事务执行，避免事务的隔离性被破坏。然后，客户端可以再次执行事务，此时，如果没有并发修改事务数据的操作了，事务就能正常执行，隔离性也得到了保证。

> **持久性**

如果 Redis 没有使用 RDB 或 AOF，那么事务的持久化属性肯定得不到保证
如果开启RDB：在一个事务执行后，而下一次的 RDB 快照还未执行前，如果发生了实例宕机，这种情况下，事务修改的数据也是不能保证持久化的。
如果开启AOF:AOF 模式的三种配置选项 no、everysec 和 always 都会存在数据丢失的情况，所以，事务的持久性属性也还是得不到保证.
所以redis无法保证持久性。

## 七、主从复制

将一台Redis服务的数据，复制到其他Redis服务器上。前者称为`主节点（master）`，后者称为`从节点（slave）`。数据的复制是`单向`的，只能从主节点到从节点。

- `读写分离`，性能扩展（应用读取多个从节点的数据，只能往主节点中写数据）
- `容灾快速恢复`。防止数据丢失，redis可以实现`高可用`，同时实现`数据的冗余备份`。

<img src="https://oss.zhulinz.top//img/image-20220531231808630.png" alt="image-20220531231808630" width="50%;" />

**主从复制的作用：**

- `数据冗余`：实现数据的热备份，也是持久化的另一种方式。
- `针对单机故障问题`：一个节点故障，其他节点可以继续提供服务，不影响用户使用。实现`快速恢复故障`，这也是服务冗余。
- `读写分离`：master服务主要用来写，slave服务主要读数据。提高服务的负载能力。
- `负载均衡`：同时配合读写分离，由主节点提供写服务，从节点提供读服务，分担服务器的负载。大大提高Redis服务的并发量和负载。
- `高可用的基石`：主从复制是哨兵和集群模式能够实施的基础。

### 7.1、Redis的同步机制

redis的主从同步机制可以确保redis的master和slave之间的数据同步。同步方式包括**全量复制和增量复制**。

> **1、全量拷贝**

在启动多个Redis实例的时候，它们相互之间就可以通过 replicaof（Redis5.0之前使用 slaveof）命令形成主库和从库的关系，之后按照三个阶段完成数据的第一次同步。

**全量拷贝的三个阶段**

![image-20220731174859026](https://oss.zhulinz.top//img/202207311749313.png)

**第一阶段是主从库间建立连接、协商同步的过程**，主要是为全量复制做准备。在这一步，从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了。

具体来说，从库给主库发送 psync 命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。psync 命令包含了主库的 runID 和复制进度 offset 两个参数。runID，是每个 Redis 实例启动时都会自动生成的一个随机 ID，用来唯一标记这个实例。当从库和主库第一次复制时，因为不知道主库的 runID，所以将 runID 设为“？”。offset，此时设为 -1，表示第一次复制。主库收到 psync 命令后，会用 FULLRESYNC 响应命令带上两个参数：主库 runID 和主库目前的复制进度 offset，返回给从库。从库收到响应后，会记录下这两个参数。这里有个地方需要注意，FULLRESYNC 响应表示第一次复制采用的全量复制，也就是说，主库会把当前所有的数据都复制给从库。

**第二阶段，主库将所有数据同步给从库**。从库收到数据后，在本地完成数据加载。这个过程依赖于内存快照生成的 RDB 文件。

具体来说，主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。从库接收到 RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空。在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求。否则，Redis 的服务就被中断了。但是，这些请求中的写操作并没有记录到刚刚生成的 RDB 文件中。为了保证主从库的数据一致性，主库会在内存中用专门的 replication buffer，记录 RDB 文件生成后收到的所有写操作。

**第三个阶段，主库会把第二阶段执行过程中新收到的写命令，再发送给从库**。具体的操作是，当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了。

> **2、增量拷贝**

1. 如果出现网络闪断或者命令丢失异常情况时，当主从连接恢复后，由于从节点之前保存了自身已复制的偏移量和主节点的运行ID。因此会把它们当做psync参数发送给主节点，要求进行部分复制操作。格式为` pxync {runId} {offset}`。
2. 主节点接到pxync命令后首先核对参数runId是否与自身一致。如果一致，说明之前复制的是当前主节点，之后根据参数offset在自身复制积压缓冲区查找，如果偏移量之后的数据存在缓冲区中，则对从节点发送 +continue响应，表示可以进行部分复制；否则进行全量复制。
3. 主节点根据偏移量把复制积压缓冲区里的数据发送给从节点，保证主从复制进入正常状态。

![image-20220731174935350](https://oss.zhulinz.top//img/202207311749694.png)

`repl_backlog_buffer`：它是为了从库断开之后，如何找到主从差异数据而设计的环形缓冲区，从而避免全量复制带来的性能开销。如果从库断开时间太久，repl_backlog_buffer环形缓冲区被主库的写命令覆盖了，那么从库连上主库后只能乖乖地进行一次全量复制，所以**repl_backlog_buffer配置尽量大一些，可以降低主从断开后全量复制的概率**。而在repl_backlog_buffer中找主从差异的数据后，如何发给从库呢？这就用到了replication buffer。

`replication buffer`：Redis和客户端通信也好，和从库通信也好，Redis都需要给分配一个 内存buffer进行数据交互，客户端是一个client，从库也是一个client，我们每个client连上Redis后，Redis都会分配一个client buffer，所有数据交互都是通过这个buffer进行的：Redis先把数据写到这个buffer中，然后再把buffer中的数据发到client socket中再通过网络发送出去，这样就完成了数据交互。所以主从在增量同步时，从库作为一个client，也会分配一个buffer，只不过这个buffer专门用来传播用户的写命令到从库，保证主从数据一致，我们通常把它叫做replication buffer。

> **如果在网络断开期间，repl_backlog_size环形缓冲区写满之后，从库是会丢失掉那部分被覆盖掉的数据，还是直接进行全量复制呢**？

对于这个问题来说，有两个关键点：

1. 一个从库如果和主库断连时间过长，造成它在主库repl_backlog_buffer的slave_repl_offset位置上的数据已经被覆盖掉了，此时从库和主库间将进行全量复制。
2. 每个从库会记录自己的slave_repl_offset，每个从库的复制进度也不一定相同。在和主库重连进行恢复时，从库会通过psync命令把自己记录的slave_repl_offset发给主库，主库会根据从库各自的复制进度，来决定这个从库可以进行增量复制，还是全量复制。

**同步故障处理**

1. **拷贝超时**

   对于数据量较大的主节点，比如生成的rdb文件超过6GB以上时要格外小心。传输文件这一步操作非常耗时，速度取决于主从节点之间网络带宽，通过细致分析 full resync和 master slave这两行日志的时间差，可以算出rdb文件从创建到传输完毕消耗的总时间。如果总时间超过了 repl-timeout 所配置的值（默认60秒），从节点将放弃接受rdb文件并清理已经下载的临时文件，导致全量复制失败。

   针对数据量较大的节点，建议调大 repl-timeout 参数防止出现全量同步数据超时。

2. **积压缓冲区拷贝溢出**

   slave节点从开始接收rdb文件到接收完成期间，主节点仍然响应读写命令，因此主节点会把这期间写入命令保存在复制积压缓冲区内，当从节点加载完rdb文件后，主节点再把缓冲区的数据发送给从节点，保证主从数据一致性。

   如果主节点创建和传输RDB的时间过长，对于高流量写入场景非常容易造成主节点复制客户端缓冲区溢出。默认配置为`client-output-buffer-limit slave 256MB 64MB 60`，如果60秒内缓冲区消耗持续大于64MB或者直接超过256MB时，主节点将直接关闭复制客户端连接，造成全量同步失败。

   因此，运维人员需要根据主节点数据量和写命令并发量调整client-output-buffer-limit slave配置，避免全量复制期间客户端缓冲区溢出。对于主节点，当发送完所有的数据后就认为全量复制完成，打印成功日志：synchronization with slave127.0.0.1：6380 succeeded

3. **slave全量同步的响应问题**

   slave节点接收完主节点传送来的全部数据后会清空自身旧数据，执行flash old data，然后加载rdb文件。对于较大的rdb文件，这一步操作依然比较耗时。

   对于线上做读写分离的场景，从节点也负责响应读命令，如果slave节点正出于全量复制阶段，那么slave节点在响应读命令可能拿到过期或错误的数据。对于这种场景，redis复制提供了slave-server-stale-data yes参数（默认开启），如果开启则slave节点依然响应所有命令。对于无法容忍不一致的应用场景可以设置no来关闭命令执行，此时从节点除了info和slaveof命令之外所有的命令只返回sync with master in progress信息。

**节点运行Id**

1. 每个Redis节点启动后，都会动态分配一个40位的十六进制字符串作为运行ID，即`{runId}`。

   > 运行ID的主要作用是用来唯一识别Redis节点，比如从节点保存主节点的运行ID识别自己正在复制的是哪个主节点。

2. 如果只使用ip+port的方式识别主节点，那么主节点重启变更了整体数据集（如替换rdb/aof文件），从节点再基于偏移量复制数据将是不安全的，因此当运行ID变化后从节点将做全量复制。

3. 可以运行info server命令查看当前节点的运行ID。

**偏移量拷贝**

1. 参与复制的主从节点都会维护自身复制偏移量，即{offset}。
2. 主节点（master）在处理完写入命令后，会把命令的字节长度做累加记录，统计信息在info relication中的 master_repl_offset 指标中。
3. 从节点（slave）在接收到主节点发送的命令后，也会累加记录自身的偏移量，统计信息在info relication命令的slave_repl_offset指标中
4. 从节点（slave）每秒钟上报自身的复制偏移量给主节点，因此主节点也会保存从节点的复制偏移量。

**积压缓冲区拷贝**

1. 存在于主节点（master），默认大小为1MB，可以通过参数rel_backlog_size来修改默认大小。
2. 复制积压缓冲区是保存在主节点上的一个固定长度的队列。当从节点（slave）连接主节点时被创建，这时主节点（master）响应写命令时，不但会把命令发送给从节点，还会写入复制积压缓冲区。
3. 由于缓冲区本质上是先进先出（FIFO）的定长队列，所以能实现保存最近已复制数据的功能，用于部分复制和复制命令丢失的数据补救。复制缓冲区相关统计信息可以通过主节点的info replication命令查看。

> **当主服务器不进行持久化时复制的安全性**

在进行主从复制设置时，强烈建议在主服务器上开启持久化，当不能这么做时，比如考虑到延迟的问题，应该将实例配置为避免自动重启。

**为什么不持久化的主服务器自动重启非常危险呢**？为了更好的理解这个问题，看下面这个失败的例子，其中主服务器和从服务器中数据库都被删除了。

- 我们设置节点A为主服务器，关闭持久化，节点B和C从节点A复制数据。
- 这时出现了一个崩溃，但Redis具有自动重启系统，重启了进程，因为关闭了持久化，节点重启后只有一个空的数据集。
- 节点B和C从节点A进行复制，现在节点A是空的，所以节点B和C上的复制数据也会被删除。
- 当在高可用系统中使用Redis Sentinel，关闭了主服务器的持久化，并且允许自动重启，这种情况是很危险的。比如主服务器可能在很短的时间就完成了重启，以至于Sentinel都无法检测到这次失败，那么上面说的这种失败的情况就发生了。

如果数据比较重要，并且在使用主从复制时关闭了主服务器持久化功能的场景中，都应该禁止实例自动重启。

> **为什么主从全量复制使用RDB而不使用AOF？**

1、RDB文件内容是经过压缩的二进制数据（不同数据类型数据做了针对性优化），文件很小。而AOF文件记录的是每一次写操作的命令，写操作越多文件会变得很大，其中还包括很多对同一个key的多次冗余操作。在主从全量数据同步时，传输RDB文件可以尽量降低对主库机器网络带宽的消耗，从库在加载RDB文件时，一是文件小，读取整个文件的速度会很快，二是因为RDB文件存储的都是二进制数据，从库直接按照RDB协议解析还原数据即可，速度会非常快，而AOF需要依次重放每个写命令，这个过程会经历冗长的处理逻辑，恢复速度相比RDB会慢得多，所以使用RDB进行主从全量复制的成本最低。

2、假设要使用AOF做全量复制，意味着必须打开AOF功能，打开AOF就要选择文件刷盘的策略，选择不当会严重影响Redis性能。而RDB只有在需要定时备份和主从全量复制数据时才会触发生成一次快照。而在很多丢失数据不敏感的业务场景，其实是不需要开启AOF的。

> **为什么还有无磁盘复制模式？**

Redis 默认是磁盘复制，但是**如果使用比较低速的磁盘，这种操作会给主服务器带来较大的压力**。Redis从2.8.18版本开始尝试支持无磁盘的复制。使用这种设置时，子进程直接将RDB通过网络发送给从服务器，不使用磁盘作为中间存储。

**无磁盘复制模式**：master创建一个新进程直接dump RDB到slave的socket，不经过主进程，不经过硬盘。适用于disk较慢，并且网络较快的时候。

使用`repl-diskless-sync`配置参数来启动无磁盘复制。

使用`repl-diskless-sync-delay` 参数来配置传输开始的延迟时间；master等待一个`repl-diskless-sync-delay`的秒数，如果没slave来的话，就直接传，后来的得排队等了; 否则就可以一起传。

> **读写分离及其中的问题?**

在主从复制基础上实现的读写分离，可以实现Redis的读负载均衡：由主节点提供写服务，由一个或多个从节点提供读服务（多个从节点既可以提高数据冗余程度，也可以最大化读负载能力）；在读负载较大的应用场景下，可以大大提高Redis服务器的并发量。下面介绍在使用Redis读写分离时，需要注意的问题。

- **延迟与不一致问题**

前面已经讲到，由于主从复制的命令传播是异步的，延迟与数据的不一致不可避免。如果应用对数据不一致的接受程度程度较低，可能的优化措施包括：优化主从节点之间的网络环境（如在同机房部署）；监控主从节点延迟（通过offset）判断，如果从节点延迟过大，通知应用不再通过该从节点读取数据；使用集群同时扩展写负载和读负载等。

在命令传播阶段以外的其他情况下，从节点的数据不一致可能更加严重，例如连接在数据同步阶段，或从节点失去与主节点的连接时等。从节点的slave-serve-stale-data参数便与此有关：它控制这种情况下从节点的表现；如果为yes（默认值），则从节点仍能够响应客户端的命令，如果为no，则从节点只能响应info、slaveof等少数命令。该参数的设置与应用对数据一致性的要求有关；如果对数据一致性要求很高，则应设置为no。

- **数据过期问题**

在单机版Redis中，存在两种删除策略：

- `惰性删除`：服务器不会主动删除数据，只有当客户端查询某个数据时，服务器判断该数据是否过期，如果过期则删除。
- `定期删除`：服务器执行定时任务删除过期数据，但是考虑到内存和CPU的折中（删除会释放内存，但是频繁的删除操作对CPU不友好），该删除的频率和执行时间都受到了限制。

在主从复制场景下，为了主从节点的数据一致性，从节点不会主动删除数据，而是由主节点控制从节点中过期数据的删除。由于主节点的惰性删除和定期删除策略，都不能保证主节点及时对过期数据执行删除操作，因此，当客户端通过Redis从节点读取数据时，很容易读取到已经过期的数据。

Redis 3.2中，从节点在读取数据时，增加了对数据是否过期的判断：如果该数据已过期，则不返回给客户端；将Redis升级到3.2可以解决数据过期问题。

- **故障切换问题**

在没有使用哨兵的读写分离场景下，应用针对读和写分别连接不同的Redis节点；当主节点或从节点出现问题而发生更改时，需要及时修改应用程序读写Redis数据的连接；连接的切换可以手动进行，或者自己写监控程序进行切换，但前者响应慢、容易出错，后者实现复杂，成本都不算低。

- **总结**

在使用读写分离之前，可以考虑其他方法增加Redis的读负载能力：如尽量优化主节点（减少慢查询、减少持久化等其他情况带来的阻塞等）提高负载能力；使用Redis集群同时提高读负载能力和写负载能力等。如果使用读写分离，可以使用哨兵，使主从节点的故障切换尽可能自动化，并减少对应用程序的侵入。

### 7.2、docker配置redis主从复制

**配置文件**

```tex
requirepass 123456 //设置密码
appendonly yes
protected-mode no  //取消保护模式
```

```tex
//docker启动redis命令
docker run -d -p 4030:6739 -v /home/redis/reids-master/redis.conf:/etc/reids/redis.conf --name redis-master redis --redis-server /etc/redis/redis.conf

// -v 宿主机目录:容器目录    --redis-server 以配置文件目录启动
```

```
//从机配置文件
requirepass 123456
appendonly yes
slaveof zhulinz.top 4030  //主机地址
masterauth 123456		//主机密码
```

**复制原理**

- Slave 启动成功连接到 master 后会发送一个 sync 命令 。
- Master 接到命令启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令， 在后台进程执行完毕之后，master 将传送整个数据文件到 slave,以完成一次完全同步。
- 全量复制：而 slave 服务在接收到数据库文件数据后，将其存盘并加载到内存中。 
- 增量复制：Master 继续将新的所有收集到的修改命令依次传给 slave,完成同步。
- 但是只要是重新连接 master,`一次完全同步（全量复制)`将被自动执行。

<img src="https://img-blog.csdnimg.cn/20210823213605854.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDE0MzExNA==,size_16,color_FFFFFF,t_70" alt="img" width="67%;" />

1. 

## 八、Redis的哨兵机制

### 8.1、哨兵的功能

![image-20220731180056922](https://oss.zhulinz.top//img/202207311800116.png)

- **监控（Monitoring）：**哨兵会不断地检查主节点和从节点是否运作正常。
- **自动故障转移（Automatic failover）**：当主节点不能正常工作时，哨兵会开始自动故障转移操作，它会将失效主节点的其中一个从节点升级为新的主节点，并让其他从节点改为复制新的主节点。
- **配置提供者（Configuration provider）**：客户端在初始化时，通过连接哨兵来获得当前Redis服务的主节点地址。
- **通知（Notification）**：哨兵可以将故障转移的结果发送给客户端。

### 8.2、主库下线的判定

- **主观下线：**任何一个哨兵都是可以监控探测，并作出Redis节点下线的判断。
- **客观下线：**由哨兵集群共同决定Redis节点是否下线。

哨兵会每隔1秒给所有主从节点发送PING命令，当主从节点收到PING命令后，会发送一个响应命令给哨兵。

![image-20220726152755159](https://oss.zhulinz.top//img/202207261527094.png)

如果主节点或者从节点没有在规定的时间内响应哨兵的 PING 命令，哨兵就会将它们标记为「**主观下线**」。这个「规定的时间」是配置项 `down-after-milliseconds` 参数设定的，单位是毫秒。

> 客观下线；客观下线只适用于主节点

之所以针对「主节点」设计「主观下线」和「客观下线」两个状态，是因为有可能「主节点」其实并没有故障，可能只是因为主节点的系统压力比较大或者网络发送了拥塞，导致主节点没有在规定时间内响应哨兵的 PING 命令。

所以，为了减少误判的情况，哨兵在部署的时候不会只部署一个节点，而是用多个节点部署成**哨兵集群**（*最少需要三台机器来部署哨兵集群*），**通过多个哨兵节点一起判断，就可以就可以避免单个哨兵因为自身网络状况不好，而误判主节点下线的情况**。同时，多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低。

> 如何判定主节点为客观下线的呢？

当一个哨兵判断主节点为「主观下线」后，就会向其他哨兵发起命令，其他哨兵收到这个命令后，就会根据自身和主节点的网络状况，做出赞成投票或者拒绝投票的响应。

![image-20220726153311602](https://oss.zhulinz.top//img/202207261533359.png)

当这个哨兵的赞同票数达到哨兵配置文件中的 quorum 配置项设定的值后，这时主节点就会被该哨兵标记为「客观下线」。

例如，现在有 3 个哨兵，quorum 配置的是 2，那么一个哨兵需要 2 张赞成票，就可以标记主节点为“客观下线”了。这 2 张赞成票包括哨兵自己的一张赞成票和另外两个哨兵的赞成票。

PS：quorum 的值一般设置为哨兵个数的二分之一加1，例如 3 个哨兵就设置 2。

哨兵判断完主节点客观下线后，哨兵就要开始在多个「从节点」中，选出一个从节点来做新主节点。

### 8.3、哨兵集群的选举？

> 判断完主库下线后，由哪个哨兵节点来执行主从切换呢？这里就需要哨兵集群的选举机制了。

- **为什么必然会出现选举/共识机制**？

为了避免哨兵的单点情况发生，所以需要一个哨兵的分布式集群。作为分布式集群，必然涉及共识问题（即选举问题）；同时故障的转移和通知都只需要一个主的哨兵节点就可以了。

- **哨兵的选举机制是什么样的**？

哨兵的选举机制其实很简单，就是一个Raft选举算法： **选举的票数大于等于num(sentinels)/2+1时，将成为领导者，如果没有超过，继续选举**

Raft算法你可以参看这篇文章[分布式算法 - Raft算法]()

- 任何一个想成为 Leader 的哨兵，要满足两个条件：
  - 第一，拿到半数以上的赞成票；
  - 第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。

以 3 个哨兵为例，假设此时的 quorum 设置为 2，那么，任何一个想成为 Leader 的哨兵只要拿到 2 张赞成票，就可以了。

> 更进一步理解
>
> 这里很多人会搞混 **判定客观下线** 和 **是否能够主从切换（用到选举机制）** 两个概念，我们再看一个例子。
>
> Redis 1主4从，5个哨兵，哨兵配置quorum为2，如果3个哨兵故障，当主库宕机时，哨兵能否判断主库“客观下线”？能否自动切换？

经过实际测试：

1、哨兵集群可以判定主库“主观下线”。由于quorum=2，所以当一个哨兵判断主库“主观下线”后，询问另外一个哨兵后也会得到同样的结果，2个哨兵都判定“主观下线”，达到了quorum的值，因此，**哨兵集群可以判定主库为“客观下线”**。

2、**但哨兵不能完成主从切换**。哨兵标记主库“客观下线后”，在选举“哨兵领导者”时，一个哨兵必须拿到超过多数的选票(5/2+1=3票)。但目前只有2个哨兵活着，无论怎么投票，一个哨兵最多只能拿到2票，永远无法达到`N/2+1`选票的结果

### 8.4、新主库的选举

- 过滤掉不健康的（下线或断线），没有回复过哨兵ping响应的从节点
- 选择`salve-priority`从节点优先级最高（redis.conf）的
- 选择复制偏移量最大，只复制最完整的从节点

![image-20220731181046840](https://oss.zhulinz.top//img/202207311810118.png)

### 8.5、故障转移

假设根据我们一开始的图：（我们假设：判断主库客观下线了，同时选出`sentinel 3`是哨兵leader）

![image-20220731181128744](https://oss.zhulinz.top//img/202207311811125.png)

**故障转移流程如下**：

![image-20220731181146703](https://oss.zhulinz.top//img/202207311811266.png)

- 将slave-1脱离原从节点（PS: 5.0 中应该是`replicaof no one`)，升级主节点，
- 将从节点slave-2指向新的主节点
- 通知客户端主节点已更换
- 将原主节点（oldMaster）变成从节点，指向新的主节点

**转移之后**

![image-20220731181229385](https://oss.zhulinz.top//img/202207311812483.png)

## 九、分片技术

## 十、Jedis测试

**Redis数据库连接**

```java
public class Connect {
    private static final String REDIS_URL = "zhulinz.top";
    private static final int PORT = 4030;
    private static final String PASSWORD = "123456";

    private static Jedis jedis;

    /**
     * redis数据库连接
     */
    public static Jedis connect() {
        jedis = new Jedis(REDIS_URL, PORT);
        jedis.auth(PASSWORD);
        //连接成功
        if (jedis.isConnected()) {
            return jedis;
        }
        return null;
    }

    public static void close() {
        jedis.close();
    }
}
```

**发送验证码**

```java
public class PhoneCode {
    private static Jedis jedis;

    public static void main(String[] args) throws InterruptedException {
        //连接redis
        jedis = Connect.connect();
        Scanner sc = new Scanner(System.in);
        System.out.println("输入手机号码:");
        String phone = sc.nextLine();
        System.out.println("正在发送验证码......");
        //获取随机验证码
        StringBuffer code = getCode();
        //号码校验
        verifyCode(phone, String.valueOf(code));
        Thread.sleep(3000);
        System.out.println("发送验证码:" + code);
        System.out.println("请输入验证码");
        String trueCode = null;
        for (int i = 0; i < 3; i++) {
            trueCode = sc.nextLine();
            if (getRedisCode(phone, trueCode)) {
                System.out.println("校验成功");
                break;
            } else {
                System.out.println("校验失败，重新输入验证码");
                continue;
            }
        }
        jedis.close();

    }

    /**
     * 验证码校验
     */
    public static boolean getRedisCode(String phone, String code) {
        //手机发送次数key
        String countKey = "VerifyCode" + phone + ":count";
        //验证码key
        String codeKey = "VerifyCode" + phone + ":code";
        String redisCode = jedis.get(codeKey);
        //判断
        if (redisCode.equals(code)) {
            return true;
        }
        return false;
    }

    /**
     * 每个手机号码每天只能发送一次，验证码放到redis中，设置过期时间
     * @param phone
     * @param code
     */
    public static void verifyCode(String phone, String code) {
        //手机发送次数key
        String countKey = "VerifyCode" + phone + ":count";
        //验证码key
        String codeKey = "VerifyCode" + phone + ":code";

        //每个手机号码只能发送三次
        String count = jedis.get(countKey);
        if (count == null) {
            //没有发送次数，第一次发送
            jedis.setex(countKey, 24 * 60 * 60, "1");
        } else if (Integer.parseInt(count) < 3) {
            //发送次数+1
            jedis.incr(countKey);
        } else {
            //发送三次  不能再发送
            System.out.println("今天发送次数已经超过三次");
            System.exit(0);
        }
        //发送验证码放到redis里面
        jedis.setex(codeKey, 120, code);
    }

    /**
     * 生成6位数字验证码
     * @return
     */
    public static StringBuffer getCode() {
        Random random = new Random();
        StringBuffer code = new StringBuffer();
        for (int i = 0; i < 6; i++) {
            int rand = random.nextInt(10);
            code.append(rand);
        }
        return code;
    }
}
```

## 十一、SpringBoot整合Redis

**依赖**

```xml
<dependencies>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
            <version>2.6.4</version>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-data-redis</artifactId>
            <version>2.6.4</version>
        </dependency>
        <dependency>
            <groupId>org.apache.commons</groupId>
            <artifactId>commons-pool2</artifactId>
            <version>2.11.1</version>
        </dependency>
        <dependency>
            <groupId>org.projectlombok</groupId>
            <artifactId>lombok</artifactId>
            <version>1.18.22</version>
            <scope>compile</scope>
        </dependency>
</dependencies>
```

Redis配置类

```java
@EnableCaching
@Configuration
public class RedisConfig extends CachingConfigurerSupport {
    @Bean
    public RedisTemplate redisTemplate(RedisConnectionFactory factory) {
        RedisTemplate template = new RedisTemplate();
        // 配置连接工厂
        template.setConnectionFactory(factory);
        //使用Jackson2JsonRedisSerializer来序列化和反序列化redis的value值（默认使用JDK的序列化方式）
        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);
        //自定义ObjectMapper
        ObjectMapper objectMapper = new ObjectMapper();
        // 指定要序列化的域，field,get和set,以及修饰符范围，ANY是都有包括private和public
        objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);
        // 指定序列化输入的类型，类必须是非final修饰的，final修饰的类，比如String,Integer等会抛出异常
        objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);
        jackson2JsonRedisSerializer.setObjectMapper(objectMapper);
        //String序列化配置
        StringRedisSerializer stringRedisSerializer = new StringRedisSerializer();
        // key采用String的序列化方式
        template.setKeySerializer(stringRedisSerializer);
        // hash的key也采用String的序列化方式
        template.setHashKeySerializer(stringRedisSerializer);
        // value序列化方式采用jackson
        template.setValueSerializer(jackson2JsonRedisSerializer);
        // hash的value序列化方式采用jackson
        template.setHashValueSerializer(jackson2JsonRedisSerializer);
        template.afterPropertiesSet();
        return template;
    }
}
```

**测试**

```java
@RestController
@RequestMapping("/redisTest")
public class RedisController {
    @Autowired
    private RedisTemplate redisTemplate;

    @GetMapping("/get")
    public String testRedis() {
        redisTemplate.opsForValue().set("k1", "v1");
        String k1 = (String) redisTemplate.opsForValue().get("k1");
        return k1;
    }
}
```

**redisTemplate封装类**		https://github.com/Anougme/-Utils/blob/master/Redis_Util/RedisUtils.java

## 十二、应用场景

使用缓存大多的目的是为了提升响应效率和并发量，减轻数据库的压力。

缓存穿透、缓存雪崩和缓存击穿的发生，都是因为在某些特殊情况下，缓存失去了预期的功能所致。当缓存失效或没有抵挡住流量，流量直接涌入到数据库中，在高并发情况下，可能直接击垮数据库，导致整个系统崩溃。

### 12.1、缓存穿透

通常流程是：一个请求过来，先查询是否在`缓存`中，如果缓存中存在，则直接返回。如果缓存中不存在对应的数据，则检索数据库，如果数据库中存在对应的数据，则更新缓存并返回结果。如果数据库中也不存在对应的数据，则`返回空或错误`。

**缓存穿透**是指`缓存`和`数据库`中都没有的数据，而用户不断发起请求。由于缓存是`不命中时被动写`的。并且出于`容错考虑`，如果从`底层数据库`中查不到数据则不写入`缓存`，这将导致这个不存在的数据每次请求都要到底层数据库中去查询，失去了缓存的意义。当高并发或有人利用不存在的Key频繁攻击时，数据库的压力骤增，甚至崩溃，这就是`缓存穿透`问题。

<img src="https://oss.zhulinz.top//img/image-20220602150658494.png"/>

**发生的场景：**

- 原来数据是存在的，但由于某些原因（`误删除、主动清理`等）在缓存和数据库层面被删除了，但前端和前置的应用程序依旧保有这些数据。
- 恶意攻击行为，利用不存在的Key或者恶意尝试导致产生`大量不存在的业务`数据请求。

**解决方案：**

- `设置并发锁`，防止大量请求数据库
- `对空值缓存`：如果一个查询返回的数据为空（不管是数据是否不存在），把这个空结果（null）进行缓存，设置空结果的过期时间会很短，最长不超过五分钟。当数据库被`写入或更新`该key的新数据时，缓存必须同时被刷新，避免数据不一致。
- `设置白名单`：利用`bitmaps`类型定义一个可访问的名单，`名单id作为bitmaps的偏移量`，每次访问和bitmaps的id进行比较，如果不对则进行拦截，不允许访问。
- `采用布隆过滤器`：布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。
- `进行实时监控`：当发现 Redis 的命中率开始急速降低，需要排查访问对象和访问的数据，和运维人员配合，可以设置黑名单限制服务。

### 12.2、缓存击穿

缓存击穿是指`缓存中没有但数据库中有的数据`（一般是缓存时间到期，`单个key`），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。

<img src="https://oss.zhulinz.top//img/image-20220602150915573.png" alt="image-20220602150915573"/>

**解决方案：**

- `预先设置热门数据`：在redis高峰访问之前，把一些热门数据提前存入到redis里面，加大这些热门数据key的时长。
- `实时调整`：现场监控哪些数据热门，实时调整key的过期时长。
- `使用互斥锁（Mutex Key）`：在缓存失效的时候（判断拿出来的值为空），不是立即去load db，先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX）去set一个mutex key，当操作返回成功时，再进行load db操作，并回设缓存，最后删除mutex key。当操作返回失败，证明有线程在load db，当前线程睡眠一段时间再去重试整个get缓存的方法。
- `提前使用互斥锁（Mutex Key）`：在value内部设置一个比缓存（Redis）过期时间短的过期时间标识，当异步线程发现该值快过期了，马上延长内置的这个时间，并重新从数据库中加载数据，设置到缓存中去。

<img src="https://oss.zhulinz.top//img/image-20220601230545180.png" alt="image-20220601230545180"/>

### 12.3、缓存雪崩

在使用缓存时，通常会对`缓存设置过期时间`，一方面目的是`保持缓存与数据库数据的一致性`，另一方面是`减少冷缓存占用过多的内存空间`。

缓存雪崩是指` Redis 服务器`在某个时间大量失效（针对`多个key缓存`），突然造成数据库访问压力急剧增大，像雪崩一样，redis雪崩危害巨大，甚至有可能服务器宕机，给公司造成巨大的经济损失。

正常情况

<img src="https://oss.zhulinz.top//img/image-20220602151310778.png" alt="image-20220602151310778" width="67%;" />

缓存失效瞬间

<img src="https://oss.zhulinz.top//img/image-20220602151450025.png" alt="image-20220602151450025" width="67%;" />

**解决方案：**

- `构建多级缓存架构`：nginx 缓存 + redis 缓存 +其他缓存（ehcache 等）。
- `使用锁或队列`：用锁或队列保证不会有`大量的线程对数据库一次性进行读写`，从而避免失效时大量的并发请求落到底层存储系统上。不适用高并发情况。
- `设置过期标志更新缓存`：记录`缓存数据是否过期（设置提前量）`，若过期会触发通知另外的线程在后台去更新实际key的缓存。
- `将缓存失效时间分散开`：比如我们可以在原有的失效时间基础上增加一个随机值，比如 1-5 分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。
- `双Key策略：`主Key设置过期时间，备Key不设置过期时间，当主Key失效时，直接返回备Key值。在更新缓存的时候，同时更新主key和备key的数据。

![image-20220726133923350](https://oss.zhulinz.top//img/202207261339883.png)

### 12.3、如何设计一个缓存策略，可以动态缓存热点数据？

由于数据存储受限，系统并不是将所有数据都需要存放到缓存中的，而**只是将其中一部分热点数据缓存起来，**所以我们要设计一个热点数据动态缓存的策略。

热点数据动态缓存的策略总体思路：**通过数据最新访问时间来做排名，并过滤掉不常访问的数据，只留下经常访问的数据。**

以电商平台场景中的例子，现在要求只缓存用户经常访问的 Top 1000 的商品。具体细节如下：

- 先通过缓存系统做一个排序队列（比如存放 1000 个商品），系统会根据商品的访问时间，更新队列信息，越是最近访问的商品排名越靠前；
- 同时系统会定期过滤掉队列中排名最后的 200 个商品，然后再从数据库中随机读取出 200 个商品加入队列中；
- 这样当请求每次到达的时候，会先从队列中获取商品 ID，如果命中，就根据 ID 再从另一个缓存数据结构中读取实际的商品信息，并返回。

在 Redis 中可以用 zadd 方法和 zrange 方法来完成排序队列和获取 200 个商品的操作。

## 十三、Redis集群

以Redis的主从复制、哨兵模式、切片模式来实现高可用Redis服务。

> 主从复制

主从复制是Redis高可用服务的最基础的保证，**实现方案**是将从前的一台的Redis服务器，同步数据到多台从Redis服务器上，即一主多从的模式，且主从服务器之间采用的`读写分离`的方式。

主服务器可以进行`读写操作`，当发生写操作时自动将写操作同步给从服务器，而从服务器一般是只读，并接受主服务器同步过来写操作命令，然后执行这条命令。（主从服务器之间的命令复制是`异步`进行的）。

![image-20220726001308111](https://oss.zhulinz.top//img/202207260013261.png)

在主从服务器命令传播阶段，主服务器收到新的写命令后，会发送给从服务器。但是，主服务器并不会等到从服务器实际执行完命令后，发送结果给客户端。而是**主服务器自己在本地执行完命令后就会向客户端发送结果**。如果从服务器还没有执行主服务器同步过来的命令，此时主从服务器之间的数据就不一致了。（`无法保证强一致性，主从数据时时刻刻保持一致，数据不一致是无法避免的`）。

> 哨兵模式

在Redis的主从服务器出现故障宕机时，需要手动进行恢复。为了解决该问题，Redis增加了哨兵模式，哨兵模式的作用是监控主从服务器，并且提供了主从节点故障转移的功能。

![image-20220726002108541](https://oss.zhulinz.top//img/202207260021144.png)

> 切片集群模式

当Redis缓存数据量大到一台服务器无法缓存时，就需要使用切片集群（Redis Cluster）方案，将数据分布在不同的服务器上，来降低系统对单主节点的依赖，从而提高Redis服务的读写性能。

Redis Cluster方案采用哈希槽（Hash Slot），来处理数据与节点之间的映射关系。在Redis Cluster方案中，`一个切片集群共有16384个哈希槽`。这些哈希槽类似于数据分区，每个键值对都会根据它的key，被映射到一个哈希槽中：

- 根据键值对的key，按照CRC16算法计算一个16bit的值。
- 再用16bit值对16384取模，得到0~16383范围内的模数，每个模数代表一个相应编号的哈希槽。

**这些哈希槽是如何被映射到具体的Redis节点上的？**两种方案：

- **平均分配：**在使用 cluster create 命令创建 Redis集群时，Redis会自动把所有哈希槽平均分布到集群节点上。（比如集群中有9个节点，则每个节点上的槽的个数为 16384/9）。
- **手动分配：**可以使用 cluster meet 命令手动建立节点间的连接，组成集群，再使用 cluster addslots 命令，指定每个节点上的哈希槽个数。

![image-20220726093120915](https://oss.zhulinz.top//img/202207260931168.png)

上图中的切片集群一共有 3 个节点，假设有 4 个哈希槽（Slot 0～Slot 3）时，我们就可以通过命令手动分配哈希槽，比如节点 1 保存哈希槽 0 和 1，节点 2 保存哈希槽 2 和 3。

```c
redis-cli -h 192.168.1.10 –p 6379 cluster addslots 0,1
redis-cli -h 192.168.1.11 –p 6379 cluster addslots 2,3
```

然后在集群运行的过程中，key1 和 key2 计算完 CRC16 值后，对哈希槽总个数 5 进行取模，再根据各自的模数结果，就可以被映射到对应的节点 1 和节点 3 上了。

需要注意的是，在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作。

## 十四、Redis的过期删除与内存淘汰

### 14.1、Redis使用的过期删除策略是什么？

Redis 是可以对 key 设置过期时间的，因此需要有相应的机制将已过期的键值对删除，而做这个工作的就是过期键值删除策略。每当我们对一个 key 设置了过期时间时，Redis 会把该 key 带上过期时间存储到一个**过期字典**（expires dict）中，也就是说「过期字典」`保存了数据库中所有 key 的过期时间`。

当我们查询一个 key 时，Redis 首先检查该 key 是否存在于过期字典中：

- 如果不在，则正常读取键值；
- 如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期。

Redis 使用的过期删除策略是**「惰性删除+定期删除」这两种策略配和使用。**

> 什么是惰性删除策略？

惰性删除策略的做法是**不主动删除全部过期键，而是每次从数据库访问 key 时，都先检测 key 是否过期，如果过期则删除 key。**

<img src="https://oss.zhulinz.top//img/202207260938553.webp" alt="惰性删除" style="width: 33%;" />

**优点：**

- 因为每次访问时，才会检查 key 是否过期，所以此策略只会使用很少的系统资源，因此，惰性删除策略对CPU时间最友好。

**缺点：**

- 如果一个 key 已经过期，而这个 key 又仍然保留在数据库中，那么只要这个过期 key 一直没有被访问，它所占用的内存就不会被释放，造成了一定空间的内存浪费。所以，惰性删除策略对内存不友好。

> 什么是定期删除策略？

**定期删除策略：**每个一段时间（默认100ms）**随机**从数据库中取出一定数量的 key 进行检查，并删除其中的过期 key。

**定期删除的流程：**

1. 从过期字典中随机抽取 20 个key；
2. 检查这 20 个key是否过期，并删除已过期的key。
3. 如果本轮检查的已过期key的数量，超过5个（20/4），也就是`已过期key的数量占比随机抽取key的数量大于25%`，则继续重复步骤1；如果已过期的key比例小于25%，则停止继续删除过期key，然后等待下一轮检查。

<img src="https://oss.zhulinz.top//img/202207260956677.webp" alt="定时删除流程" style="width:30%;" />



**优点：**

- 通过限制删除操作执行的时长和频率，来减少删除操作对CPU的影响，同时也能删除一部分过期的数据来减少过期键对空间的无效占用。

**缺点：**

- 难以确定删除操作执行的时长和频率。如果执行的太频繁，就会对CPU不太好；如果执行的太少，就和惰性删除差不多了，过期key占用的内存不会及时得到释放。

### 14.2、Redis持久化时，对过期键会如何处理？

RDB文件分为两个阶段，RDB文件`生成阶段`和`加载阶段`

- **RDB生成阶段：**从内存状态持久化成RDB（文件）的时候，会对 key 进行过期检查，过期的键不会被保存到新的RDB文件中，因此Redis中的过期键不会对生成新RDB文件产生任何影响。
- **RDB加载阶段：**RDB加载阶段时，要看服务器是主服务器还是从服务器：
  - **主服务器：**主服务器运行模式的情况下，载入RDB文件时，程序会对文件中保存的键进行检查，**过期键不会被载入到数据库中**。所以过期键不会对载入RDB文件的主服务器造成影响。
  - **从服务器：**从服务器运行模式下，载入RDB文件，**不论键是否过期都会被载入到数据库中**。但由于主从服务器在进行数据同步时，**从服务器的数据会被清空**。所以一般来说，过期键载入RDB文件的从服务器也不会造成影响。



AOF文件分为两个阶段，`AOF文件写入阶段`和`AOF重写阶段`

- **AOF文件写入阶段：**当Redis以AOF模式持久化时，如果数据库某个过期键还没被删除，那么`AOF文件会保留此过期键`，当此过期键被删除后，Redis会向`AOF文件追加一条DEL命令`来显式地删除该键值。
- **AOF重写阶段：**执行AOF重写时，会对Redis中的`键值对进行检查`，`已过期的键不会被保存到重写后的AOF文件中`。因此不会对AOF重写造成任何影响。

### 14.3、Redis主从模式中，对过期键会如何处理？

当 Redis 运行在主从模式下时，**从库不会进行过期扫描，从库对过期的处理是被动的**。也就是即使从库中的 key 过期了，如果有客户端访问从库时，依然可以得到 key 对应的值，像未过期的键值对一样返回。

从库的过期键处理依靠主服务器控制，**主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库**，从库通过执行这条 del 指令来删除过期的 key。

## 十五、数据库与缓存保证一致性？

### 15.1、先更新数据库，还是先更新缓存？

> 先更新数据库，再更新缓存

可能由于并发问题导致缓存与数据库中的数据不一致的现象。

举例：两个请求A和B，同时更新同一条数据，则可能出现以下的顺序：

![image-20220726134419713](https://oss.zhulinz.top//img/202207261344271.png)

A请求先将数据库更新为1，在还没来得及更新缓存时，B请求将数据库的数据更新为2，紧接着也将缓存中数据更新为2，然后A请求更新缓存中的数据为1。此时数据库中的数据为2，而缓存中的数据是1，就出现了缓存和数据库中的数据不一致的现象。（由于并发问题，数据库更新与缓存更新是两个操作，不具有原子性）

> 先更新缓存，再更新数据库

与以上出现的现象可能相同

![image-20220726134822176](https://oss.zhulinz.top//img/202207261348247.png)

**所以，无论是先更新数据库，还是先更新缓存。这两个方案都存在并发问题。当两个请求并发更新同一条数据的时候，可能会出现缓存和数据库中的数据不一致的现象。**

### 15.2、先更新数据库，还是先删除缓存？

> 旁路缓存策略（Cache Aside）：不更新缓存，而是缓存中的数据。然后，到读取数据的时候，发现缓存中没了数据之后，再从数据库中读取数据，更新到缓存中。

![image-20220726135232605](https://oss.zhulinz.top//img/202207261352833.png)

**写策略的步骤：**

- 更新数据库中的数据；
- 删除缓存中的数据。

**读策略的步骤：**

- 如果读取的数据命中了缓存，则直接返回数据；
- 如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写入到缓存，并且返回给用户。

> 先删除缓存，再更新数据库

假设某个用户的年龄是 20，请求 A 要更新用户年龄为 21，所以它会删除缓存中的内容。这时，另一个请求 B 要读取这个用户的年龄，它查询缓存发现未命中后，会从数据库中读取到年龄为 20，并且写入到缓存中，然后请求 A 继续更改数据库，将用户的年龄更新为 21。

![image-20220726143421756](https://oss.zhulinz.top//img/202207261434872.png)

最终，该用户年龄在缓存中是 20（旧值），在数据库中是 21（新值），缓存和数据库的数据不一致。**先删除缓存，再更新数据库，在「读 + 写」并发的时候，还是会出现缓存和数据库的数据不一致的问题**。

> 先更新数据库，再删除缓存

假如某个用户数据在缓存中不存在，请求 A 读取数据时从数据库中查询到年龄为 20，在未写入缓存中时另一个请求 B 更新数据。它更新数据库中的年龄为 21，并且清空缓存。这时请求 A 把从数据库中读到的年龄为 20 的数据写入到缓存中。

![image-20220726144044729](https://oss.zhulinz.top//img/202207261440922.png)

最终，该用户年龄在缓存中是 20（旧值），在数据库中是 21（新值），缓存和数据库数据不一致。由此可见先更新数据库，再删除缓存也是会出现数据不一致性的问题。**但是在实际中，这个问题出现的概率并不高。**

**因为缓存的写入通常要远远快于数据库的写入**，在实际中很难出现请求B已经更新了数据库并且删除了缓存，请求A才更新完缓存的情况。而一旦请求A早于请求B删除缓存之前更新了缓存，那么接下来的请求就会因为缓存不命中而从数据库中重新读取数据，所以不会出现这种不一致的情况。

**先更新数据库，再删除缓存**的方案是可以保证数据一致性的。

> 关于先更新数据库，再删除缓存方案，如何保证两个操作都能执行成功？

![image-20220726145239543](https://oss.zhulinz.top//img/202207261452488.png)

在更新完数据库之后，删除缓存失败。此时数据库中的数据是新值，缓存中的值是旧值，就会出现数据不一致的问题。

解决问题的方法：

- 重试机制
- 订阅MySQL binlog，再操作缓存。

> 重试机制

我们可以引入**消息队列**，将第二个操作（删除缓存）要操作的数据加入到消息队列，由消费者来操作数据。

- 如果应用**删除缓存失败**，可以从消息队列中重新读取数据，然后再次删除缓存，这个就是**重试机制**。当然，如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。
- 如果**删除缓存成功**，就要把数据从消息队列中移除，避免重复操作，否则就继续重试。

![image-20220726150159823](https://oss.zhulinz.top//img/202207261502545.png)

> 订阅MySQL binglog，再操作缓存

「**先更新数据库，再删缓存**」的策略的第一步是更新数据库，那么更新数据库成功，就会产生一条变更日志，记录在 binlog 里。

于是我们就可以通过订阅 binlog 日志，拿到具体要操作的数据，然后再执行缓存删除，阿里巴巴开源的 Canal 中间件就是基于这个实现的。

Canal 模拟 MySQL 主从复制的交互协议，把自己伪装成一个 MySQL 的从节点，向 MySQL 主节点发送 dump 请求，MySQL 收到请求后，就会开始推送 Binlog 给 Canal，Canal 解析 Binlog 字节流之后，转换为便于读取的结构化数据，供下游程序订阅使用。

![image-20220726150242699](https://oss.zhulinz.top//img/202207261502302.png)

## 参考文章

- [♥Redis教程 - Redis知识体系详解♥](https://www.pdai.tech/md/db/nosql-redis/db-redis-overview.html)
- [图解Redis](https://xiaolincoding.com/redis/)
- [Redis相关面试题](/7-八股文/6、Redis相关面试题)

